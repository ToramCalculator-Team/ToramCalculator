/**
 * @file generator.js
 * @description å¼€å‘ç¯å¢ƒç”Ÿæˆå™¨
 *
 * ä¸»è¦åŠŸèƒ½ï¼š
 * å°†baseSchemaå’Œenumsç»“åˆï¼Œç”ŸæˆserverSchemaå’ŒclientSchema
 * 1.sqlå¤„ç†
 * æ ¹æ®serverSchemaå’ŒclientSchemaç”ŸæˆserverDB/init.sqlå’ŒclientDB/init.sql
 * å¯¹ç”Ÿæˆçš„clientDB/init.sqlè¿›è¡Œè½¬æ¢ï¼Œä½¿å…¶èƒ½é…åˆåŒæ­¥æ¶æ„å·¥ä½œ
 * ä¿®å¤serverDB/init.sqlå’ŒclientDB/init.sqlä¸­çš„è¡¨åå¼•ç”¨ï¼Œä½¿å…¶èƒ½æ­£ç¡®å¼•ç”¨
 * 2.ç”Ÿæˆkyselyç±»å‹
 * 3.ç”Ÿæˆzodç±»å‹
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { createRequire } from "module";
import { execSync } from "child_process";
import { SchemaAnalyzer } from "./utils/SchemaAnalyzer.js";

const require = createRequire(import.meta.url);
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * æ–‡ä»¶è·¯å¾„é…ç½®
 */
const PATHS = {
  // è¾“å…¥æ–‡ä»¶
  enums: path.join(__dirname, "enums.ts"),
  baseSchema: path.join(__dirname, "baseSchema.prisma"),

  // ç”Ÿæˆçš„æ–‡ä»¶
  serverDB: {
    sql: path.join(__dirname, "generated/serverDB/init.sql"),
    tempSchema: path.join(__dirname, "temp_server_schema.prisma"),
  },
  clientDB: {
    sql: path.join(__dirname, "generated/clientDB/init.sql"),
    tempSchema: path.join(__dirname, "temp_client_schema.prisma"),
  },
  zod: {
    schemas: path.join(__dirname, "generated/zod/index.ts"),
  },
  kysely: {
    types: path.join(__dirname, "generated/kysely/kyesely.ts"),
    enums: path.join(__dirname, "generated/kysely/enums.ts"),
  },
};

/**
 * æ–‡ä»¶ç®¡ç†å·¥å…·ç±»
 */
class FileManager {
  /**
   * ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
   */
  static ensureDirectories() {
    const dirs = [path.dirname(PATHS.serverDB.sql), path.dirname(PATHS.clientDB.sql), path.dirname(PATHS.zod.schemas)];

    dirs.forEach((dir) => {
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }
  });
}

  /**
   * æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   */
  static cleanupTempFiles() {
    const tempFiles = [PATHS.serverDB.tempSchema, PATHS.clientDB.tempSchema];

    tempFiles.forEach((file) => {
      if (fs.existsSync(file)) {
        fs.unlinkSync(file);
      }
    });
  }

  /**
   * å®‰å…¨å†™å…¥æ–‡ä»¶
   * @param {string} filePath - æ–‡ä»¶è·¯å¾„
   * @param {string} content - æ–‡ä»¶å†…å®¹
   * @param {string} encoding - ç¼–ç æ ¼å¼
   */
  static safeWriteFile(filePath, content, encoding = "utf-8") {
    try {
      // ç¡®ä¿ç›®å½•å­˜åœ¨
      const dir = path.dirname(filePath);
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }

      fs.writeFileSync(filePath, content, encoding);
    } catch (error) {
      console.error(`å†™å…¥æ–‡ä»¶å¤±è´¥: ${filePath}`, error);
      throw error;
    }
  }

  /**
   * å®‰å…¨è¯»å–æ–‡ä»¶
   * @param {string} filePath - æ–‡ä»¶è·¯å¾„
   * @param {string} encoding - ç¼–ç æ ¼å¼
   * @returns {string} æ–‡ä»¶å†…å®¹
   */
  static safeReadFile(filePath, encoding = "utf-8") {
    try {
      return fs.readFileSync(filePath, encoding);
    } catch (error) {
      console.error(`è¯»å–æ–‡ä»¶å¤±è´¥: ${filePath}`, error);
      throw error;
    }
  }
}

/**
 * å·¥å…·å‡½æ•°é›†åˆ
 */
const utils = {
  /**
   * è½¬æ¢ä¸º PascalCase
   * @param {string} str - è¾“å…¥å­—ç¬¦ä¸²
   * @returns {string} PascalCase å­—ç¬¦ä¸²
   */
  toPascalCase: (str) => str.toLowerCase().replace(/(?:^|_)([a-z])/g, (_, c) => c.toUpperCase()),
  
  /**
   * æ‰§è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯
   * @param {string} command - è¦æ‰§è¡Œçš„å‘½ä»¤
   * @param {Object} options - æ‰§è¡Œé€‰é¡¹
   */
  execCommand: (command, options = {}) => {
    try {
      execSync(command, { stdio: "inherit", ...options });
    } catch (error) {
      console.error(`å‘½ä»¤æ‰§è¡Œå¤±è´¥: ${command}`, error);
      throw error;
    }
  },
};

/**
 * æšä¸¾å¤„ç†å™¨
 * è´Ÿè´£å¤„ç† Prisma schema ä¸­çš„æšä¸¾å®šä¹‰
 */
class EnumProcessor {
  constructor() {
    this.extractedEnums = new Map();
    this.enumModels = new Map();
    this.enumDefinitions = new Map();
  }

  /**
   * å¤„ç†æšä¸¾å®šä¹‰
   * @returns {EnumProcessor} å½“å‰å®ä¾‹ï¼Œæ”¯æŒé“¾å¼è°ƒç”¨
   */
  processEnums() {
    const enumsModule = require(PATHS.enums);
    for (const [key, value] of Object.entries(enumsModule)) {
      const enumName = utils.toPascalCase(key);
      if (Array.isArray(value)) {
        this.extractedEnums.set(
          enumName,
          value.flatMap((v) => (v.startsWith("...") ? enumsModule[v.slice(3)] || [] : v)),
        );
      }
    }
    return this;
  }

  /**
   * å¤„ç† schema æ–‡ä»¶
   * @returns {Object} å¤„ç†ç»“æœ
   */
  processSchema() {
    let schemaContent = FileManager.safeReadFile(PATHS.baseSchema);
    const lines = schemaContent.split("\n");
    let updatedSchema = "";
    let currentModel = "";
    let skipGenerators = false;
    let inKyselyGenerator = false;
    let kyselyGenerator = "";
    let clientGenerators = [];
    let tempGenerator = [];

    for (const line of lines) {
      const trimmed = line.trim();

      // å¤„ç† generator å—
      if (trimmed.startsWith("generator ")) {
        if (trimmed.includes("kysely")) {
          inKyselyGenerator = true;
          tempGenerator = [line];
        } else {
          skipGenerators = true;
          tempGenerator = [line];
        }
        continue;
      }

      // æ”¶é›† generator å—å†…å®¹
      if (inKyselyGenerator || skipGenerators) {
        tempGenerator.push(line);
        if (trimmed === "}") {
          if (inKyselyGenerator) {
            kyselyGenerator += tempGenerator.join("\n") + "\n";
            inKyselyGenerator = false;
          } else {
            clientGenerators.push(tempGenerator.join("\n"));
            skipGenerators = false;
          }
        }
        continue;
      }

      // å¤„ç†æ¨¡å‹å®šä¹‰
      const modelMatch = trimmed.match(/^model (\w+) \{$/);
      if (modelMatch) {
        currentModel = modelMatch[1];
        this.enumModels.set(currentModel, new Map());
        updatedSchema += line + "\n";
        continue;
      }

      // å¤„ç†æ¨¡å‹ç»“æŸ
      if (trimmed === "}") {
        currentModel = "";
        updatedSchema += line + "\n";
        continue;
      }

      // å¤„ç†æšä¸¾å­—æ®µ
      let newLine = line;
      const enumMatch = line.match(/(\w+)\s+\w+\s+\/\/ Enum (\w+)/);
      if (enumMatch && currentModel) {
        const [, fieldName, originalEnumName] = enumMatch;
        const pascalCaseEnum = utils.toPascalCase(originalEnumName);

        if (this.extractedEnums.has(pascalCaseEnum)) {
          newLine = line.replace("String", pascalCaseEnum);
          if (!this.enumDefinitions.has(pascalCaseEnum)) {
            this.enumDefinitions.set(
              pascalCaseEnum,
              `enum ${pascalCaseEnum} {\n  ${this.extractedEnums.get(pascalCaseEnum).join("\n  ")}\n}`,
            );
          }
          this.enumModels.get(currentModel).set(fieldName, originalEnumName);
        }
      }

      updatedSchema += newLine + "\n";
    }

    return {
      updatedSchema,
      kyselyGenerator,
      clientGenerators,
    };
  }
}

/**
 * SQL ç”Ÿæˆå™¨
 * è´Ÿè´£ç”Ÿæˆæ•°æ®åº“åˆå§‹åŒ– SQL è„šæœ¬
 */
class SQLGenerator {
  /**
   * ç”Ÿæˆ SQL æ–‡ä»¶
   * @param {string} updatedSchema - æ›´æ–°åçš„ schema å†…å®¹
   * @param {string} kyselyGenerator - Kysely generator é…ç½®
   * @param {Array} clientGenerators - å®¢æˆ·ç«¯ generators é…ç½®
   * @param {Map} enumDefinitions - æšä¸¾å®šä¹‰
   */
  static generate(updatedSchema, kyselyGenerator, clientGenerators, enumDefinitions) {
    // ç”Ÿæˆæœ€ç»ˆçš„ schema æ–‡ä»¶
    const finalSchema = updatedSchema + "\n" + Array.from(enumDefinitions.values()).join("\n\n");

    // åˆ›å»ºä¸´æ—¶ schema æ–‡ä»¶
    FileManager.safeWriteFile(PATHS.serverDB.tempSchema, finalSchema);
    FileManager.safeWriteFile(
      PATHS.clientDB.tempSchema,
      clientGenerators.join("\n") + "\n" + kyselyGenerator + finalSchema,
    );

    // ç”Ÿæˆ SQL æ–‡ä»¶
    utils.execCommand(
      `npx prisma migrate diff --from-empty --to-schema-datamodel ${PATHS.serverDB.tempSchema} --script > ${PATHS.serverDB.sql}`,
    );
    utils.execCommand(
      `npx prisma migrate diff --from-empty --to-schema-datamodel ${PATHS.clientDB.tempSchema} --script > ${PATHS.clientDB.sql}`,
    );

    // è½¬æ¢clientDB/init.sql
    this.transformClientSql();

    // ç”Ÿæˆ Kysely ç±»å‹
    this.generateKyselyTypes();

    // ä¿®å¤å…³ç³»è¡¨åç§°
    this.fixRelationTableNames(updatedSchema);
  }

  /**
   * å°†clientDB/init.sqlè½¬æ¢ä¸ºæ”¯æŒåŒæ­¥æ¶æ„çš„sql
   */
  static transformClientSql() {
    const initSQLFilePath = PATHS.clientDB.sql;
    // è¯»å–æ–‡ä»¶å†…å®¹
    let initContent = fs.readFileSync(initSQLFilePath, "utf-8");

    // åˆ é™¤æ‰€æœ‰ `ALTER TABLE` è¯­å¥ä¸­æ¶‰åŠ `FOREIGN KEY` çš„è¡Œ
    initContent = initContent.replace(/ALTER TABLE .* FOREIGN KEY.*;\n?/g, "");

    // **åˆ é™¤å­¤ç«‹çš„ `-- AddForeignKey` è¡Œ**
    initContent = initContent.replace(/-- AddForeignKey\s*\n?/g, "");

    // åˆ é™¤æ‰€æœ‰çš„ `CREATE INDEX` è¯­å¥
    initContent = initContent.replace(/CREATE INDEX.*;\n?/g, "");
    initContent = initContent.replace(/CREATE UNIQUE INDEX.*;\n?/g, "");

    // **åˆ é™¤å­¤ç«‹çš„ `-- CreateIndex` è¡Œ**
    initContent = initContent.replace(/-- CreateIndex\s*\n?/g, "");

    // **å»é™¤å¯èƒ½å¤šä½™çš„ç©ºè¡Œ**
    // initContent = initContent.replace(/\n{2,}/g, "\n");

    fs.writeFileSync(initSQLFilePath, initContent, "utf-8");

    console.log("âœ… å¤–é”®çº¦æŸåŠç´¢å¼•å·²åˆ é™¤ï¼");

    ///////////////// å°†sqlè½¬æ¢æˆ  *_synced è¡¨ï¼ˆåªè¯»å‰¯æœ¬ï¼‰ï¼›*_local è¡¨ï¼ˆæœ¬åœ°çŠ¶æ€ + ä¹è§‚æ›´æ–°ï¼‰ï¼›VIEWï¼ˆåˆå¹¶è¯»å–è§†å›¾ï¼‰ï¼› ////////////////////

    /**
     * ä»åŸå§‹ CREATE TABLE è¯­å¥ä¸­æå–ç»“æ„ä¿¡æ¯
     */
    function parseCreateTable(sql) {
      const match = sql.match(/CREATE TABLE "?(\w+)"?\s*\(([\s\S]+?)\);/i);
      if (!match) return null;
      const [, tableName, body] = match;
      const lines = body
        .split(/\r?\n/)
        .map((line) => line.trim())
        .filter(Boolean);

      const columns = [];
      const constraints = [];

      for (const line of lines) {
        if (line.startsWith("CONSTRAINT") || line.startsWith("PRIMARY KEY") || line.startsWith("UNIQUE")) {
          constraints.push(line.replace(/,+$/, ""));
        } else {
          columns.push(line.replace(/,+$/, ""));
        }
      }

      return { tableName, columns, constraints };
    }

    /**
     * é‡å‘½åä¸»é”®çº¦æŸ
     */
    function renamePrimaryKeyConstraint(constraints, newName) {
      return constraints.map((constraint) => {
        return constraint.replace(/CONSTRAINT\s+"[^"]*"\s+PRIMARY KEY/i, `CONSTRAINT "${newName}" PRIMARY KEY`);
      });
    }

    /**
     * ç”Ÿæˆ synced è¡¨ç»“æ„
     */
    function generateSyncedTable({ tableName, columns, constraints }) {
      const renamedConstraints = renamePrimaryKeyConstraint(constraints, `${tableName}_synced_pkey`);
      const syncedCols = [...columns, `"write_id" UUID`];
      return `CREATE TABLE IF NOT EXISTS "${tableName}_synced" (\n  ${[...syncedCols, ...renamedConstraints].join(",\n  ")}\n);`;
    }

    /**
     * ç”Ÿæˆ local è¡¨ç»“æ„
     */
    function generateLocalTable({ tableName, columns, constraints }) {
      const localCols = columns.map((col) => {
        const [name, type] = col.split(/\s+/, 2);
        if (name === "id") return col; // ä¿ç•™ä¸»é”®åŸæ ·
        return `${name} ${type}`;
      });

      const renamedConstraints = renamePrimaryKeyConstraint(constraints, `${tableName}_local_pkey`);

      return `CREATE TABLE IF NOT EXISTS "${tableName}_local" (\n  ${[
        ...localCols,
        `"changed_columns" TEXT[]`,
        `"is_deleted" BOOLEAN NOT NULL DEFAULT FALSE`,
        `"write_id" UUID NOT NULL`,
        ...renamedConstraints,
      ].join(",\n  ")}
);`;
    }

    /**
     * ç”Ÿæˆè§†å›¾
     */
    function generateView({ tableName, columns, constraints }) {
      const colNames = columns.map((col) => col.split(/\s+/, 1)[0].replace(/^"|"$/g, ""));

      // è§£æä¸»é”®å­—æ®µ
      const pkConstraint = constraints.find((c) => c.includes("PRIMARY KEY"));
      const pkCols = pkConstraint
        ? pkConstraint
            .match(/\(([^)]+)\)/)[1]
            .split(",")
            .map((s) => s.trim().replace(/"/g, ""))
        : [];

      // å¯¹äºå…³è”è¡¨ï¼Œå¦‚æœæ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨æ‰€æœ‰åˆ—ä½œä¸ºä¸»é”®
      if (pkCols.length === 0 && tableName.startsWith("_")) {
        pkCols.push(...colNames);
      }

      // å¦‚æœä»ç„¶æ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨ UNION ALL æ–¹å¼
      if (pkCols.length === 0) {
        return `
CREATE OR REPLACE VIEW "${tableName}" AS
  SELECT
  ${colNames.map((name) => `   synced."${name}" AS "${name}"`).join(",\n")}
  FROM "${tableName}_synced" AS synced
  UNION ALL
  SELECT
  ${colNames.map((name) => `   local."${name}" AS "${name}"`).join(",\n")}
  FROM "${tableName}_local" AS local
  WHERE local."is_deleted" = FALSE;`;
      }

      const selectLines = colNames.map((name) =>
        pkCols.includes(name)
          ? `   COALESCE(local."${name}", synced."${name}") AS "${name}"`
          : `   CASE
    WHEN '${name}' = ANY(local.changed_columns)
      THEN local."${name}"
      ELSE synced."${name}"
    END AS "${name}"`,
      );

      const joinCondition = pkCols.map((pk) => `synced."${pk}" = local."${pk}"`).join(" AND ");
      const whereCondition = `(${pkCols.map((pk) => `local."${pk}" IS NULL`).join(" OR ")} OR local."is_deleted" = FALSE)`;

      const view = `
CREATE OR REPLACE VIEW "${tableName}" AS
  SELECT
  ${selectLines.join(",\n")}
  FROM "${tableName}_synced" AS synced
  FULL OUTER JOIN "${tableName}_local" AS local
  ON ${joinCondition}
  WHERE ${whereCondition};`;

      const jsonFields = colNames.map((name) => `'${name}', NEW."${name}"`).join(",\n      ");
      const updateJsonFields = colNames
        .map((name) => `'${name}', COALESCE(NEW."${name}", local."${name}")`)
        .join(",\n      ");

      const changedColsCheck = colNames
        .filter((c) => !pkCols.includes(c))
        .map(
          (name) => `
    IF NEW."${name}" IS DISTINCT FROM synced."${name}" THEN
      changed_cols := array_append(changed_cols, '${name}');
    END IF;`,
        )
        .join("");

      const triggerFnInsert = `
CREATE OR REPLACE FUNCTION ${tableName}_insert_trigger()
RETURNS TRIGGER AS $$
DECLARE
    local_write_id UUID := gen_random_uuid();
    changed_cols TEXT[] := ARRAY[]::TEXT[];
BEGIN
    -- Add all non-primary key columns to changed_columns
    ${colNames
      .filter((name) => !pkCols.includes(name))
      .map((name) => `changed_cols := array_append(changed_cols, '${name}');`)
      .join("\n    ")}

    INSERT INTO "${tableName}_local" (
    ${colNames.map((name) => `"${name}"`).join(", ")},
    changed_columns,
    write_id
    )
    VALUES (
    ${colNames.map((name) => `NEW."${name}"`).join(", ")},
    changed_cols,
    local_write_id
    );

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'insert',
    jsonb_build_object(
        ${jsonFields}
    ),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;`;

      const updateSetLines =
        colNames
          .filter((c) => !pkCols.includes(c))
          .map(
            (name) =>
              `
    "${name}" = CASE WHEN NEW."${name}" IS DISTINCT FROM synced."${name}" THEN NEW."${name}" ELSE local."${name}" END`,
          )
          .join(",") || "-- no non-pk fields";

      const triggerFnUpdate = `
CREATE OR REPLACE FUNCTION ${tableName}_update_trigger()
RETURNS TRIGGER AS $$
DECLARE
    synced "${tableName}_synced"%ROWTYPE;
    local "${tableName}_local"%ROWTYPE;
    changed_cols TEXT[] := ARRAY[]::TEXT[];
    local_write_id UUID := gen_random_uuid();
BEGIN
    SELECT * INTO synced FROM "${tableName}_synced" WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    SELECT * INTO local FROM "${tableName}_local" WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    ${changedColsCheck || "-- no non-pk fields to track"}
    IF NOT FOUND THEN
    INSERT INTO "${tableName}_local" (
        ${colNames.map((name) => `"${name}"`).join(", ")},
        changed_columns,
        write_id
    )
    VALUES (
        ${colNames.map((name) => `NEW."${name}"`).join(", ")},
        changed_cols,
        local_write_id
    );
    ELSE
    UPDATE "${tableName}_local"
    SET
        ${updateSetLines},
        changed_columns = (
        SELECT array_agg(DISTINCT col) FROM (
            SELECT unnest(local.changed_columns) AS col
            UNION
            SELECT unnest(changed_cols) AS col
        ) AS cols
        ),
        write_id = local_write_id
    WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    END IF;

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'update',
    jsonb_strip_nulls(jsonb_build_object(
        ${updateJsonFields}
    )),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;`;

      const triggerFnDelete = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_trigger()
RETURNS TRIGGER AS $$
DECLARE
    local_write_id UUID := gen_random_uuid();
BEGIN
    IF EXISTS (SELECT 1 FROM "${tableName}_local" WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")}) THEN
    UPDATE "${tableName}_local"
    SET is_deleted = TRUE,
        write_id = local_write_id
    WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")};
    ELSE
    INSERT INTO "${tableName}_local" (
        ${pkCols.join(", ")},
        "is_deleted",
        "write_id"
    )
    VALUES (
        ${pkCols.map((pk) => `OLD."${pk}"`).join(", ")},
        TRUE,
        local_write_id
    );
    END IF;

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'delete',
    jsonb_build_object(${pkCols.map((pk) => `'${pk}', OLD."${pk}"`).join(", ")}),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN OLD;
END;
$$ LANGUAGE plpgsql;`;

      const triggers = `
CREATE OR REPLACE TRIGGER ${tableName}_insert
INSTEAD OF INSERT ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_insert_trigger();

CREATE OR REPLACE TRIGGER ${tableName}_update
INSTEAD OF UPDATE ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_update_trigger();

CREATE OR REPLACE TRIGGER ${tableName}_delete
INSTEAD OF DELETE ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_trigger();
`;

      const syncedInsertUpdateCleanupFn = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_local_on_synced_insert_and_update_trigger()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM "${tableName}_local"
  WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")}
    AND write_id IS NOT NULL
    AND write_id = NEW.write_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
`;

      const syncedDeleteCleanupFn = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_local_on_synced_delete_trigger()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM "${tableName}_local"
  WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")};
  RETURN OLD;
END;
$$ LANGUAGE plpgsql;
`;

      const syncedTriggers = `
CREATE OR REPLACE TRIGGER delete_local_on_synced_insert
AFTER INSERT OR UPDATE ON "${tableName}_synced"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_local_on_synced_insert_and_update_trigger();

CREATE OR REPLACE TRIGGER delete_local_on_synced_delete
AFTER DELETE ON "${tableName}_synced"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_local_on_synced_delete_trigger();
`;

      return [
        view,
        triggerFnInsert,
        triggerFnUpdate,
        triggerFnDelete,
        triggers,
        syncedInsertUpdateCleanupFn,
        syncedDeleteCleanupFn,
        syncedTriggers,
      ].join("\n");
    }

    // åŒ¹é…å®Œæ•´çš„ SQL å—ï¼ˆåŒ…æ‹¬æ³¨é‡Šï¼‰
    const blocks = initContent
      .split(/(?=^--|^CREATE\s|^ALTER\s|^DROP\s)/gim)
      .map((block) => block.trim())
      .filter(Boolean);

    const output = [];

    for (const block of blocks) {
      if (/^CREATE\s+TABLE/i.test(block)) {
        const parsed = parseCreateTable(block);
        if (!parsed) {
          output.push(`-- âš ï¸ æ— æ³•è§£æçš„è¡¨å®šä¹‰ä¿ç•™å¦‚ä¸‹ï¼š\n${block}`);
          continue;
        }

        const { tableName } = parsed;

        output.push(`-- ${tableName}`);

        // output.push(`-- DROP original "${tableName}"`);
        // output.push(`DROP TABLE IF EXISTS "${tableName}";\n`);

        output.push(generateSyncedTable(parsed));

        output.push(generateLocalTable(parsed));

        output.push(generateView(parsed));
      } else {
        // å…¶ä½™ SQL ä¿ç•™
        output.push(block);
      }
    }

    const changesTable = `CREATE TABLE IF NOT EXISTS changes (
  id BIGSERIAL PRIMARY KEY,
  table_name TEXT NOT NULL,
  operation TEXT NOT NULL,
  value JSONB NOT NULL,
  write_id UUID NOT NULL,
  transaction_id XID8 NOT NULL
);

CREATE OR REPLACE FUNCTION changes_notify_trigger()
RETURNS TRIGGER AS $$
BEGIN
  NOTIFY changes;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE TRIGGER changes_notify
AFTER INSERT ON changes
FOR EACH ROW
EXECUTE FUNCTION changes_notify_trigger();
`;

    fs.writeFileSync(initSQLFilePath, output.join("\n") + changesTable, "utf-8");
    console.log(`âœ… å·²è½¬æ¢initSQL ${initSQLFilePath}`);
  }

  /**
   * ç”Ÿæˆ Kysely ç±»å‹
   */
  static generateKyselyTypes() {
    utils.execCommand("prisma generate --schema=db/temp_client_schema.prisma --generator=kysely");
  }

  /**
   * ä¿®å¤å…³ç³»è¡¨åç§°
   * @param {string} updatedSchema - æ›´æ–°åçš„ schema å†…å®¹
   */
  static fixRelationTableNames(updatedSchema) {
    // ä½¿ç”¨ SchemaAnalyzer è‡ªåŠ¨æ£€æµ‹éœ€è¦ä¿®å¤çš„å…³ç³»è¡¨åç§°
    const schemaAnalysis = SchemaAnalyzer.analyzeSchema(updatedSchema);
    const relationTables = schemaAnalysis.relationTables;

    // ä¿®å¤ SQL ä¸­çš„è¡¨åå¼•ç”¨
    const fixTableNames = (sql) => {
      let fixedSql = sql;
      relationTables.forEach((tableName) => {
        // æ›¿æ¢è¡¨åå¼•ç”¨ï¼Œç¡®ä¿ä½¿ç”¨åŒå¼•å·åŒ…è£¹
        const regex = new RegExp(`\\b${tableName.toLowerCase()}\\b`, "g");
        fixedSql = fixedSql.replace(regex, `"${tableName}"`);
      });
      return fixedSql;
    };

    // è¯»å–å¹¶ä¿®å¤ SQL æ–‡ä»¶
    const serverSql = FileManager.safeReadFile(PATHS.serverDB.sql);
    const clientSql = FileManager.safeReadFile(PATHS.clientDB.sql);

    // å†™å…¥ä¿®å¤åçš„ SQL æ–‡ä»¶
    FileManager.safeWriteFile(PATHS.serverDB.sql, fixTableNames(serverSql));
    FileManager.safeWriteFile(PATHS.clientDB.sql, fixTableNames(clientSql));
  }
}

/**
 * Zod Schema ç”Ÿæˆå™¨
 * è´Ÿè´£ç”Ÿæˆ Zod éªŒè¯æ¨¡å¼
 */
class ZodGenerator {
  /**
   * ç”Ÿæˆ Zod schemas
   */
  static generate() {
    // ä» db/kysely/enums.ts ç”Ÿæˆ zod æšä¸¾
    const enumSchemas = this.generateEnumSchemas();

    // ä» Kysely ç±»å‹å®šä¹‰ç”Ÿæˆ Zod schemas
    const generatedSchemas = this.generateModelSchemas();

    // ç”Ÿæˆæœ€ç»ˆçš„ Zod schemas æ–‡ä»¶å†…å®¹
    const zodFileContent = `// ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹
import { z } from "zod";

${enumSchemas}
${generatedSchemas}
`;

    // å†™å…¥ Zod schemas æ–‡ä»¶
    FileManager.safeWriteFile(PATHS.zod.schemas, zodFileContent);
  }

  /**
   * ç”Ÿæˆæšä¸¾ schemas
   * @returns {string} æšä¸¾ schemas å†…å®¹
   */
  static generateEnumSchemas() {
    let enumSchemas = "";
    const enumMap = new Map();

    if (fs.existsSync(PATHS.kysely.enums)) {
      const enumsContent = FileManager.safeReadFile(PATHS.kysely.enums);
      const enumConstRegex = /export const (\w+) = \{([\s\S]*?)\} as const;/g;
      let match;

      while ((match = enumConstRegex.exec(enumsContent)) !== null) {
        const enumName = match[1];
        const body = match[2];
        const valueRegex = /['"]?\w+['"]?\s*:\s*['"]([^'"]+)['"]/g;
        let valueMatch;
        const values = [];

        while ((valueMatch = valueRegex.exec(body)) !== null) {
          values.push(valueMatch[1]);
        }

        if (values.length > 0) {
          enumSchemas += `export const ${enumName}Schema = z.enum([${values.map((v) => `"${v}"`).join(", ")}]);\n`;
          enumSchemas += `export type ${enumName}Type = z.infer<typeof ${enumName}Schema>;\n\n`;
          enumMap.set(enumName.toLowerCase(), values);
        }
      }
    }

    return enumSchemas;
  }

  /**
   * ç”Ÿæˆæ¨¡å‹ schemas
   * @returns {string} æ¨¡å‹ schemas å†…å®¹
   */
  static generateModelSchemas() {
    const kyselyTypes = FileManager.safeReadFile(PATHS.kysely.types);
    const parsedTypes = this.parseTypes(kyselyTypes);
    
    // ç”Ÿæˆ Zod schemas
    return Object.entries(parsedTypes)
      .map(([typeName, fields]) => {
        const schemaName = `${typeName.toLowerCase()}Schema`;
        const fieldsStr = Object.entries(fields)
          .map(([fieldName, zodType]) => `  ${fieldName}: ${zodType}`)
          .join(",\n");

        return `export const ${schemaName} = z.object({\n${fieldsStr}\n});`;
      })
      .join("\n\n");
  }

  /**
   * è½¬æ¢ç±»å‹åˆ° Zod ç±»å‹
   * @param {string} type - TypeScript ç±»å‹
   * @returns {string} Zod ç±»å‹
   */
  static convertTypeToZod(type) {
    // å¤„ç†è”åˆç±»å‹
    if (type.includes("|")) {
      const types = type.split("|").map((t) => t.trim());
      // å¦‚æœåŒ…å« nullï¼Œä½¿ç”¨ nullable()
      if (types.includes("null")) {
        const nonNullTypes = types.filter((t) => t !== "null");
        if (nonNullTypes.length === 1) {
          return `${this.convertTypeToZod(nonNullTypes[0])}.nullable()`;
        }
        return `z.union([${nonNullTypes.map((t) => this.convertTypeToZod(t)).join(", ")}]).nullable()`;
      }
      return `z.union([${types.map((t) => this.convertTypeToZod(t)).join(", ")}])`;
    }

    // å¤„ç†æ•°ç»„ç±»å‹
    if (type.endsWith("[]")) {
      const baseType = type.slice(0, -2);
      return `z.array(${this.convertTypeToZod(baseType)})`;
    }

    // å¤„ç†åŸºæœ¬ç±»å‹
    switch (type) {
      case "string":
        return "z.string()";
      case "number":
        return "z.number()";
      case "boolean":
        return "z.boolean()";
      case "Date":
      case "Timestamp":
        return "z.date()";
      case "JsonValue":
      case "InputJsonValue":
      case "unknown":
        return `z.lazy(() => z.union([
          z.string(),
          z.number(),
          z.boolean(),
          z.literal(null),
          z.record(z.lazy(() => z.union([z.any(), z.literal(null)]))),
          z.array(z.lazy(() => z.union([z.any(), z.literal(null)])))
        ]))`;
      default:
        // æ£€æŸ¥æ˜¯å¦æ˜¯æšä¸¾ç±»å‹
        if (type.endsWith("Type")) {
          const enumName = type.replace("Type", "");
          // ç¡®ä¿æšä¸¾åç§°é¦–å­—æ¯å¤§å†™
          const pascalCaseEnum = enumName.charAt(0).toUpperCase() + enumName.slice(1);
          return `${pascalCaseEnum}TypeSchema`;
        }
        // æ£€æŸ¥æ˜¯å¦æ˜¯å­—é¢é‡ç±»å‹
        if (type.startsWith('"') && type.endsWith('"')) {
          return `z.literal(${type})`;
        }
        // å¯¹äºæœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„ JSON ç±»å‹
        return `z.lazy(() => z.union([
          z.string(),
          z.number(),
          z.boolean(),
          z.literal(null),
          z.record(z.lazy(() => z.union([z.any(), z.literal(null)]))),
          z.array(z.lazy(() => z.union([z.any(), z.literal(null)])))
        ]))`;
    }
  }

  /**
   * è§£æå­—æ®µ
   * @param {string} fieldsStr - å­—æ®µå­—ç¬¦ä¸²
   * @returns {Object} å­—æ®µæ˜ å°„
   */
  static parseFields(fieldsStr) {
    const fields = {};
    const fieldRegex = /(\w+)(\?)?:\s*([^;]+);/g;
    let match;

    while ((match = fieldRegex.exec(fieldsStr)) !== null) {
      const [, name, optional, type] = match;
      const zodType = this.convertTypeToZod(type.trim());
      fields[name] = optional ? `${zodType}.nullable()` : zodType;
    }

    return fields;
  }

  /**
   * è§£æç±»å‹å®šä¹‰
   * @param {string} kyselyTypes - Kysely ç±»å‹å†…å®¹
   * @returns {Object} ç±»å‹æ˜ å°„
   */
  static parseTypes(kyselyTypes) {
    const types = {};
    const typeRegex = /export\s+type\s+(\w+)\s*=\s*\{([\s\S]*?)\};/g;
    let match;

    while ((match = typeRegex.exec(kyselyTypes)) !== null) {
      const [, typeName, fieldsStr] = match;
      
      // è·³è¿‡ä¸éœ€è¦çš„ç±»å‹
      if (
        typeName === "Generated" ||
        typeName === "Timestamp" ||
        typeName.includes("Relation") ||
        typeName.includes("To") ||
        typeName.includes("_create_data") ||
        typeName.includes("_update_data")
      ) {
        continue;
      }

      types[typeName] = this.parseFields(fieldsStr);
    }

    return types;
  }
}

/**
 * ä¸»å‡½æ•°
 * åè°ƒæ‰€æœ‰ç”Ÿæˆå™¨çš„æ‰§è¡Œ
 */
async function main() {
  try {
    console.log("Generator Start");

    // ç¡®ä¿ç›®å½•å­˜åœ¨
    FileManager.ensureDirectories();

    // å¤„ç†æšä¸¾
    const enumProcessor = new EnumProcessor();
    const { updatedSchema, kyselyGenerator, clientGenerators } = enumProcessor.processEnums().processSchema();

    // ç”Ÿæˆ SQL æ–‡ä»¶
    SQLGenerator.generate(updatedSchema, kyselyGenerator, clientGenerators, enumProcessor.enumDefinitions);
    console.log("âœ… SQL æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼");

    // ç”Ÿæˆ Zod schemas
    ZodGenerator.generate();
    console.log("âœ… Zod schemas ç”Ÿæˆå®Œæˆï¼");

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    FileManager.cleanupTempFiles();
    console.log("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆï¼");

    console.log("ğŸ‰ æ•°æ®åº“ Schema ç”Ÿæˆå®Œæˆï¼");
  } catch (error) {
    console.error("ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:", error);
    process.exit(1);
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°
if (import.meta.url === `file://${process.argv[1]}`) {
main();
}
