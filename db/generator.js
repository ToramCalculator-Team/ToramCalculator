/**
 * @file generator.js
 * @description å¼€å‘ç¯å¢ƒç”Ÿæˆå™¨
 *
 * ä¸»è¦åŠŸèƒ½ï¼š
 * å°†baseSchemaå’Œenumsç»“åˆï¼Œç”ŸæˆserverSchemaå’ŒclientSchema
 * 1.sqlå¤„ç†
 * æ ¹æ®serverSchemaå’ŒclientSchemaç”ŸæˆserverDB/init.sqlå’ŒclientDB/init.sql
 * å¯¹ç”Ÿæˆçš„clientDB/init.sqlè¿›è¡Œè½¬æ¢ï¼Œä½¿å…¶èƒ½é…åˆåŒæ­¥æ¶æ„å·¥ä½œ
 * ä¿®å¤serverDB/init.sqlå’ŒclientDB/init.sqlä¸­çš„è¡¨åå¼•ç”¨ï¼Œä½¿å…¶èƒ½æ­£ç¡®å¼•ç”¨
 * 2.ç”Ÿæˆkyselyç±»å‹
 * 3.ç”Ÿæˆzodç±»å‹
 * 4.ç”ŸæˆQueryBuilderè§„åˆ™
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { createRequire } from "module";
import { execSync } from "child_process";
import { SchemaAnalyzer } from "./utils/SchemaAnalyzer.js";

const require = createRequire(import.meta.url);
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * æ–‡ä»¶è·¯å¾„é…ç½®
 */
const PATHS = {
  // è¾“å…¥æ–‡ä»¶
  enums: path.join(__dirname, "enums.ts"),
  baseSchema: path.join(__dirname, "baseSchema.prisma"),

  // ç”Ÿæˆçš„æ–‡ä»¶
  serverDB: {
    sql: path.join(__dirname, "generated/serverDB/init.sql"),
    tempSchema: path.join(__dirname, "temp_server_schema.prisma"),
  },
  clientDB: {
    sql: path.join(__dirname, "generated/clientDB/init.sql"),
    tempSchema: path.join(__dirname, "temp_client_schema.prisma"),
  },
  zod: {
    schemas: path.join(__dirname, "generated/zod/index.ts"),
  },
  kysely: {
    types: path.join(__dirname, "generated/kysely/kyesely.ts"),
    enums: path.join(__dirname, "generated/kysely/enums.ts"),
  },
  queryBuilder: {
    rules: path.join(__dirname, "generated/queryBuilderRules.ts"),
  },
};

/**
 * é€šç”¨å·¥å…·å‡½æ•°
 */
const utils = {
  /**
   * è½¬æ¢ä¸º PascalCase
   * @param {string} str - è¾“å…¥å­—ç¬¦ä¸²
   * @returns {string} PascalCase å­—ç¬¦ä¸²
   */
  toPascalCase: (str) => str.toLowerCase().replace(/(?:^|_)([a-z])/g, (_, c) => c.toUpperCase()),
  
  /**
   * è½¬æ¢ä¸º camelCase
   * @param {string} str - è¾“å…¥å­—ç¬¦ä¸²
   * @returns {string} camelCase å­—ç¬¦ä¸²
   */
  toCamelCase: (str) => str.toLowerCase().replace(/(?:^|_)([a-z])/g, (_, c) => c.toUpperCase()).replace(/^[A-Z]/, c => c.toLowerCase()),
  
  /**
   * ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æ ‡ç­¾
   * @param {string} fieldName - å­—æ®µå
   * @returns {string} ç”¨æˆ·å‹å¥½æ ‡ç­¾
   */
  generateLabel: (fieldName) => {
    return fieldName
      .replace(/([A-Z])/g, ' $1')
      .replace(/^./, str => str.toUpperCase())
      .trim();
  },

  /**
   * ä»æ³¨é‡Šä¸­æå–å­—æ®µæè¿°
   * @param {string} comment - æ³¨é‡Šå†…å®¹
   * @returns {string} å­—æ®µæè¿°
   */
  extractDescription: (comment) => {
    if (!comment) return '';
    return comment.replace(/\/\/\s*/, '').trim();
  },

  /**
   * æ‰§è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯
   * @param {string} command - è¦æ‰§è¡Œçš„å‘½ä»¤
   * @param {Object} options - æ‰§è¡Œé€‰é¡¹
   */
  execCommand: (command, options = {}) => {
    try {
      execSync(command, { stdio: "inherit", ...options });
    } catch (error) {
      console.error(`å‘½ä»¤æ‰§è¡Œå¤±è´¥: ${command}`, error);
      throw error;
    }
  },

  /**
   * å®‰å…¨çš„æ–‡ä»¶å†™å…¥
   * @param {string} filePath - æ–‡ä»¶è·¯å¾„
   * @param {string} content - æ–‡ä»¶å†…å®¹
   * @param {string} encoding - ç¼–ç æ ¼å¼
   */
  safeWriteFile: (filePath, content, encoding = "utf-8") => {
    try {
      const dir = path.dirname(filePath);
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
      fs.writeFileSync(filePath, content, encoding);
    } catch (error) {
      console.error(`å†™å…¥æ–‡ä»¶å¤±è´¥: ${filePath}`, error);
      throw error;
    }
  },

  /**
   * å®‰å…¨çš„æ–‡ä»¶è¯»å–
   * @param {string} filePath - æ–‡ä»¶è·¯å¾„
   * @param {string} encoding - ç¼–ç æ ¼å¼
   * @returns {string} æ–‡ä»¶å†…å®¹
   */
  safeReadFile: (filePath, encoding = "utf-8") => {
    try {
      return fs.readFileSync(filePath, encoding);
    } catch (error) {
      console.error(`è¯»å–æ–‡ä»¶å¤±è´¥: ${filePath}`, error);
      throw error;
    }
  },

  /**
   * ç¡®ä¿ç›®å½•å­˜åœ¨
   */
  ensureDirectories: () => {
    const dirs = [
      path.dirname(PATHS.serverDB.sql), 
      path.dirname(PATHS.clientDB.sql), 
      path.dirname(PATHS.zod.schemas),
      path.dirname(PATHS.queryBuilder.rules)
    ];

    dirs.forEach((dir) => {
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
    });
  },

  /**
   * æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   */
  cleanupTempFiles: () => {
    const tempFiles = [PATHS.serverDB.tempSchema, PATHS.clientDB.tempSchema];

    tempFiles.forEach((file) => {
      if (fs.existsSync(file)) {
        fs.unlinkSync(file);
      }
    });
  },
};

// é€šç”¨æ“ä½œç¬¦é…ç½®
const COMMON_OPERATORS = {
  // å­—ç¬¦ä¸²æ“ä½œç¬¦
  string: [
    { name: "equals", value: "equals", label: "Equals" },
    { name: "!=", value: "!=", label: "Not Equals" },
    { name: "contains", value: "contains", label: "Contains" },
    { name: "beginsWith", value: "beginsWith", label: "Begins With" },
    { name: "endsWith", value: "endsWith", label: "Ends With" },
  ],
  // æ•°å­—æ“ä½œç¬¦
  number: [
    { name: "equals", value: "equals", label: "Equals" },
    { name: "!=", value: "!=", label: "Not Equals" },
    { name: "greater_than", value: "greater_than", label: "Greater Than" },
    { name: "less_than", value: "less_than", label: "Less Than" },
    { name: "between", value: "between", label: "Between" },
  ],
  // æ—¥æœŸæ“ä½œç¬¦
  date: [
    { name: "equals", value: "equals", label: "Equals" },
    { name: "!=", value: "!=", label: "Not Equals" },
    { name: "greater_than", value: "greater_than", label: "Greater Than" },
    { name: "less_than", value: "less_than", label: "Less Than" },
    { name: "between", value: "between", label: "Between" },
  ],
  // å¸ƒå°”æ“ä½œç¬¦
  boolean: [
    { name: "equals", value: "equals", label: "Equals" },
    { name: "!=", value: "!=", label: "Not Equals" },
  ],
  // æšä¸¾æ“ä½œç¬¦
  enum: [
    { name: "equals", value: "equals", label: "Equals" },
    { name: "!=", value: "!=", label: "Not Equals" },
    { name: "in", value: "in", label: "In" },
    { name: "not_in", value: "not_in", label: "Not In" },
  ],
};

// ç±»å‹è½¬æ¢å™¨ä¼˜åŒ–
const typeConverter = {
  prismaToQueryBuilder: (prismaType, isOptional = false) => {
    const baseType = typeConverter.extractBaseType(prismaType);
    
    if (typeConverter.isEnumType(prismaType)) {
      return {
        valueEditorType: "select",
        inputType: "text",
        comparator: "enum",
        operators: COMMON_OPERATORS.enum,
      };
    }
    
    if (typeConverter.isRelationType(prismaType)) {
      return {
        valueEditorType: "text",
        inputType: "text",
        comparator: "string",
        operators: COMMON_OPERATORS.string,
      };
    }
    
    if (typeConverter.isArrayType(prismaType)) {
      return {
        valueEditorType: "text",
        inputType: "text",
        comparator: "string",
        operators: COMMON_OPERATORS.string,
      };
    }
    
    switch (baseType) {
      case "String":
        return {
          valueEditorType: "text",
          inputType: "text",
          comparator: "string",
          operators: COMMON_OPERATORS.string,
        };
      case "Int":
      case "Float":
      case "Decimal":
        return {
          valueEditorType: "text",
          inputType: "number",
          comparator: "number",
          operators: COMMON_OPERATORS.number,
        };
      case "Boolean":
        return {
          valueEditorType: "checkbox",
          inputType: "checkbox",
          comparator: "boolean",
          operators: COMMON_OPERATORS.boolean,
        };
      case "DateTime":
        return {
          valueEditorType: "text",
          inputType: "datetime-local",
          comparator: "date",
          operators: COMMON_OPERATORS.date,
        };
      case "Json":
        return {
          valueEditorType: "text",
          inputType: "text",
          comparator: "string",
          operators: COMMON_OPERATORS.string,
        };
      default:
        return {
          valueEditorType: "text",
          inputType: "text",
          comparator: "string",
          operators: COMMON_OPERATORS.string,
        };
    }
  },
  
  isEnumType: (type) => {
    return type.includes("Enum") || type.includes("enum");
  },
  
  isRelationType: (type) => {
    return type.includes("Relation") || type.includes("relation");
  },
  
  isArrayType: (type) => {
    return type.includes("[]") || type.includes("Array");
  },
  
  extractBaseType: (type) => {
    // ç§»é™¤å¯é€‰æ ‡è®°å’Œæ•°ç»„æ ‡è®°
    let baseType = type.replace(/\?$/, "").replace(/\[\]$/, "");
    
    // å¦‚æœæ˜¯æšä¸¾ç±»å‹ï¼Œæå–åŸºç¡€ç±»å‹
    if (baseType.includes("Enum")) {
      return "Enum";
    }
    
    // å¦‚æœæ˜¯å…³ç³»ç±»å‹ï¼Œè¿”å› String
    if (baseType.includes("Relation")) {
      return "String";
    }
    
    return baseType;
  },
};

/**
 * Schema è§£æå·¥å…·
 */
const schemaParser = {
  /**
   * è§£ææ¨¡å‹å®šä¹‰
   * @param {string} schemaContent - Schema å†…å®¹
   * @returns {Array} æ¨¡å‹å®šä¹‰æ•°ç»„
   */
  parseModels: (schemaContent) => {
    const models = [];
    const lines = schemaContent.split('\n');
    let currentModel = null;
    let inModel = false;

    for (const line of lines) {
      const trimmed = line.trim();
      
      // æ£€æµ‹æ¨¡å‹å¼€å§‹
      const modelMatch = trimmed.match(/^model (\w+) \{$/);
      if (modelMatch) {
        currentModel = {
          name: modelMatch[1],
          fields: [],
          comments: []
        };
        inModel = true;
        continue;
      }

      // æ£€æµ‹æ¨¡å‹ç»“æŸ
      if (trimmed === '}' && inModel) {
        if (currentModel) {
          models.push(currentModel);
        }
        currentModel = null;
        inModel = false;
        continue;
      }

      // æ”¶é›†æ¨¡å‹å†…å®¹
      if (inModel && currentModel) {
        // æ£€æµ‹å­—æ®µå®šä¹‰
        const fieldMatch = trimmed.match(/^(\w+)\s+(\w+(?:\?|\[\])?)(?:\s+\/\/\s*Enum\s+(\w+))?(?:\s+@relation.*)?$/);
        if (fieldMatch) {
          const [, fieldName, fieldType, enumType] = fieldMatch;
          
          // è·³è¿‡å…³ç³»å­—æ®µ
          if (!typeConverter.isRelationType(trimmed)) {
            currentModel.fields.push({
              name: fieldName,
              type: fieldType,
              enumType: enumType,
              isOptional: fieldType.includes('?'),
              isArray: typeConverter.isArrayType(fieldType),
              comments: currentModel.comments.slice()
            });
          }
          currentModel.comments = [];
        } else if (trimmed.startsWith('//') && inModel) {
          currentModel.comments.push(trimmed);
        }
      }
    }

    return models;
  },

  /**
   * è§£ææšä¸¾å®šä¹‰
   * @param {string} schemaContent - Schema å†…å®¹
   * @returns {Object} æšä¸¾å®šä¹‰æ˜ å°„
   */
  parseEnums: (schemaContent) => {
    const enums = {};
    const enumRegex = /enum\s+(\w+)\s*\{([\s\S]*?)\}/g;
    let match;

    while ((match = enumRegex.exec(schemaContent)) !== null) {
      const [, enumName, enumBody] = match;
      const values = enumBody
        .split('\n')
        .map(line => line.trim())
        .filter(line => line && !line.startsWith('//'))
        .map(line => line.replace(',', '').replace(/"/g, ''));

      enums[enumName] = values;
    }

    return enums;
  }
};

// æšä¸¾å¤„ç†å™¨ä¼˜åŒ–
class EnumProcessor {
  constructor() {
    this.extractedEnums = new Map();
    this.enumModels = new Map();
    this.enumDefinitions = new Map();
    this.enumTypeToNameMap = new Map(); // å­˜å‚¨æšä¸¾ç±»å‹ååˆ°æšä¸¾åçš„æ˜ å°„
  }

  /**
   * å¤„ç†æšä¸¾å®šä¹‰
   * @returns {EnumProcessor} å½“å‰å®ä¾‹ï¼Œæ”¯æŒé“¾å¼è°ƒç”¨
   */
  processEnums() {
    try {
      // ç›´æ¥å¯¼å…¥ enums.ts æ¨¡å—ï¼Œè®© JS å¼•æ“å¤„ç†æ‰€æœ‰å±•å¼€æ“ä½œç¬¦
    const enumsModule = require(PATHS.enums);
      
      // å¤„ç†æ‰€æœ‰å¯¼å‡ºçš„æšä¸¾
    for (const [key, value] of Object.entries(enumsModule)) {
        // è·³è¿‡ç±»å‹å®šä¹‰ï¼ˆä»¥ Type ç»“å°¾çš„ï¼‰
        if (key.endsWith('Type')) continue;
        
      const enumName = utils.toPascalCase(key);
      if (Array.isArray(value)) {
          // ç›´æ¥ä½¿ç”¨æ•°ç»„å€¼ï¼ŒJS å¼•æ“å·²ç»å¤„ç†äº†æ‰€æœ‰å±•å¼€æ“ä½œç¬¦
          this.extractedEnums.set(enumName, value);
        }
      }
      console.log(`ğŸ“Š æˆåŠŸè§£æ ${this.extractedEnums.size} ä¸ªæšä¸¾ï¼ˆä½¿ç”¨æ¨¡å—å¯¼å…¥æ–¹å¼ï¼‰`);
      
    } catch (error) {
      console.error("âŒ æ— æ³•å¯¼å…¥ enums.ts æ¨¡å—:", error.message);
      throw error;
    }
    
    return this;
  }

  /**
   * å¤„ç† schema æ–‡ä»¶
   * @returns {Object} å¤„ç†ç»“æœ
   */
  processSchema() {
    let schemaContent = utils.safeReadFile(PATHS.baseSchema);
    const lines = schemaContent.split("\n");
    let updatedSchema = "";
    let currentModel = "";
    let skipGenerators = false;
    let inKyselyGenerator = false;
    let kyselyGenerator = "";
    let clientGenerators = [];
    let tempGenerator = [];

    for (const line of lines) {
      const trimmed = line.trim();

      // å¤„ç† generator å—
      if (trimmed.startsWith("generator ")) {
        if (trimmed.includes("kysely")) {
          inKyselyGenerator = true;
          tempGenerator = [line];
        } else {
          skipGenerators = true;
          tempGenerator = [line];
        }
        continue;
      }

      // æ”¶é›† generator å—å†…å®¹
      if (inKyselyGenerator || skipGenerators) {
        tempGenerator.push(line);
        if (trimmed === "}") {
          if (inKyselyGenerator) {
            kyselyGenerator += tempGenerator.join("\n") + "\n";
            inKyselyGenerator = false;
          } else {
            clientGenerators.push(tempGenerator.join("\n"));
            skipGenerators = false;
          }
        }
        continue;
      }

      // å¤„ç†æ¨¡å‹å®šä¹‰
      const modelMatch = trimmed.match(/^model (\w+) \{$/);
      if (modelMatch) {
        currentModel = modelMatch[1];
        this.enumModels.set(currentModel, new Map());
        updatedSchema += line + "\n";
        continue;
      }

      // å¤„ç†æ¨¡å‹ç»“æŸ
      if (trimmed === "}") {
        currentModel = "";
        updatedSchema += line + "\n";
        continue;
      }

      // å¤„ç†æšä¸¾å­—æ®µ
      let newLine = line;
      const enumMatch = line.match(/(\w+)\s+\w+\s+\/\/ Enum (\w+)/);
      if (enumMatch && currentModel) {
        const [, fieldName, originalEnumName] = enumMatch;
        const pascalCaseEnum = utils.toPascalCase(originalEnumName);

        if (this.extractedEnums.has(pascalCaseEnum)) {
          newLine = line.replace("String", pascalCaseEnum);
          if (!this.enumDefinitions.has(pascalCaseEnum)) {
            this.enumDefinitions.set(
              pascalCaseEnum,
              `enum ${pascalCaseEnum} {\n  ${this.extractedEnums.get(pascalCaseEnum).join("\n  ")}\n}`,
            );
          }
          this.enumModels.get(currentModel).set(fieldName, originalEnumName);
          
          // å»ºç«‹æšä¸¾ç±»å‹ååˆ°æšä¸¾åçš„æ˜ å°„
          this.enumTypeToNameMap.set(originalEnumName, pascalCaseEnum);
        }
      }

      updatedSchema += newLine + "\n";
    }

    return {
      updatedSchema,
      kyselyGenerator,
      clientGenerators,
    };
  }

  /**
   * æ ¹æ®æšä¸¾ç±»å‹åæŸ¥æ‰¾å¯¹åº”çš„æšä¸¾å
   * @param {string} enumType - æšä¸¾ç±»å‹åï¼ˆå¦‚ "CHARACTER_PERSONALITY_TYPE"ï¼‰
   * @returns {string|null} å¯¹åº”çš„æšä¸¾åï¼ˆå¦‚ "Characterpersonalitytype"ï¼‰
   */
  findEnumName(enumType) {
    // å»ºç«‹æšä¸¾ç±»å‹ååˆ°æšä¸¾åçš„æ˜ å°„
    const enumTypeToNameMap = new Map();
    
    // éå†æ‰€æœ‰æå–çš„æšä¸¾ï¼Œå»ºç«‹æ˜ å°„å…³ç³»
    for (const [enumName, values] of this.extractedEnums) {
      // å°†æšä¸¾åè½¬æ¢ä¸ºå¯èƒ½çš„æšä¸¾ç±»å‹å
      const possibleEnumTypes = [
        enumName.toUpperCase(), // ç›´æ¥è½¬å¤§å†™
        enumName.toUpperCase().replace(/TYPE$/, '_TYPE'), // æ·»åŠ  _TYPE åç¼€
        enumName.toUpperCase().replace(/TYPE$/, '') + '_TYPE', // æ›¿æ¢ TYPE ä¸º _TYPE
      ];
      
      for (const possibleEnumType of possibleEnumTypes) {
        enumTypeToNameMap.set(possibleEnumType, enumName);
      }
    }
    
    return enumTypeToNameMap.get(enumType) || null;
  }
}

/**
 * SQL ç”Ÿæˆå™¨
 * è´Ÿè´£ç”Ÿæˆæ•°æ®åº“åˆå§‹åŒ– SQL è„šæœ¬
 */
class SQLGenerator {
  /**
   * ç”Ÿæˆ SQL æ–‡ä»¶
   * @param {string} updatedSchema - æ›´æ–°åçš„ schema å†…å®¹
   * @param {string} kyselyGenerator - Kysely generator é…ç½®
   * @param {Array} clientGenerators - å®¢æˆ·ç«¯ generators é…ç½®
   * @param {Map} enumDefinitions - æšä¸¾å®šä¹‰
   */
  static generate(updatedSchema, kyselyGenerator, clientGenerators, enumDefinitions) {
    // ç”Ÿæˆæœ€ç»ˆçš„ schema æ–‡ä»¶
    const finalSchema = updatedSchema + "\n" + Array.from(enumDefinitions.values()).join("\n\n");

    // åˆ›å»ºä¸´æ—¶ schema æ–‡ä»¶
    utils.safeWriteFile(PATHS.serverDB.tempSchema, finalSchema);
    utils.safeWriteFile(
      PATHS.clientDB.tempSchema,
      clientGenerators.join("\n") + "\n" + kyselyGenerator + finalSchema,
    );

    // ç”Ÿæˆ SQL æ–‡ä»¶
    utils.execCommand(
      `npx prisma migrate diff --from-empty --to-schema-datamodel ${PATHS.serverDB.tempSchema} --script > ${PATHS.serverDB.sql}`,
    );
    utils.execCommand(
      `npx prisma migrate diff --from-empty --to-schema-datamodel ${PATHS.clientDB.tempSchema} --script > ${PATHS.clientDB.sql}`,
    );

    // è½¬æ¢clientDB/init.sql
    this.transformClientSql();

    // ä¿®å¤å…³ç³»è¡¨åç§°
    this.fixRelationTableNames(updatedSchema);
  }

  /**
   * å°†clientDB/init.sqlè½¬æ¢ä¸ºæ”¯æŒåŒæ­¥æ¶æ„çš„sql
   */
  static transformClientSql() {
    const initSQLFilePath = PATHS.clientDB.sql;
    // è¯»å–æ–‡ä»¶å†…å®¹
    let initContent = fs.readFileSync(initSQLFilePath, "utf-8");

    // åˆ é™¤æ‰€æœ‰ `ALTER TABLE` è¯­å¥ä¸­æ¶‰åŠ `FOREIGN KEY` çš„è¡Œ
    initContent = initContent.replace(/ALTER TABLE .* FOREIGN KEY.*;\n?/g, "");

    // **åˆ é™¤å­¤ç«‹çš„ `-- AddForeignKey` è¡Œ**
    initContent = initContent.replace(/-- AddForeignKey\s*\n?/g, "");

    // åˆ é™¤æ‰€æœ‰çš„ `CREATE INDEX` è¯­å¥
    initContent = initContent.replace(/CREATE INDEX.*;\n?/g, "");
    initContent = initContent.replace(/CREATE UNIQUE INDEX.*;\n?/g, "");

    // **åˆ é™¤å­¤ç«‹çš„ `-- CreateIndex` è¡Œ**
    initContent = initContent.replace(/-- CreateIndex\s*\n?/g, "");

    // **å»é™¤å¯èƒ½å¤šä½™çš„ç©ºè¡Œ**
    // initContent = initContent.replace(/\n{2,}/g, "\n");

    fs.writeFileSync(initSQLFilePath, initContent, "utf-8");

    console.log("âœ… å¤–é”®çº¦æŸåŠç´¢å¼•å·²åˆ é™¤ï¼");

    ///////////////// å°†sqlè½¬æ¢æˆ  *_synced è¡¨ï¼ˆåªè¯»å‰¯æœ¬ï¼‰ï¼›*_local è¡¨ï¼ˆæœ¬åœ°çŠ¶æ€ + ä¹è§‚æ›´æ–°ï¼‰ï¼›VIEWï¼ˆåˆå¹¶è¯»å–è§†å›¾ï¼‰ï¼› ////////////////////

    /**
     * ä»åŸå§‹ CREATE TABLE è¯­å¥ä¸­æå–ç»“æ„ä¿¡æ¯
     */
    function parseCreateTable(sql) {
      const match = sql.match(/CREATE TABLE "?(\w+)"?\s*\(([\s\S]+?)\);/i);
      if (!match) return null;
      const [, tableName, body] = match;
      const lines = body
        .split(/\r?\n/)
        .map((line) => line.trim())
        .filter(Boolean);

      const columns = [];
      const constraints = [];

      for (const line of lines) {
        if (line.startsWith("CONSTRAINT") || line.startsWith("PRIMARY KEY") || line.startsWith("UNIQUE")) {
          constraints.push(line.replace(/,+$/, ""));
        } else {
          columns.push(line.replace(/,+$/, ""));
        }
      }

      return { tableName, columns, constraints };
    }

    /**
     * é‡å‘½åä¸»é”®çº¦æŸ
     */
    function renamePrimaryKeyConstraint(constraints, newName) {
      return constraints.map((constraint) => {
        return constraint.replace(/CONSTRAINT\s+"[^"]*"\s+PRIMARY KEY/i, `CONSTRAINT "${newName}" PRIMARY KEY`);
      });
    }

    /**
     * ç”Ÿæˆ synced è¡¨ç»“æ„
     */
    function generateSyncedTable({ tableName, columns, constraints }) {
      const renamedConstraints = renamePrimaryKeyConstraint(constraints, `${tableName}_synced_pkey`);
      const syncedCols = [...columns, `"write_id" UUID`];
      return `CREATE TABLE IF NOT EXISTS "${tableName}_synced" (\n  ${[...syncedCols, ...renamedConstraints].join(",\n  ")}\n);`;
    }

    /**
     * ç”Ÿæˆ local è¡¨ç»“æ„
     */
    function generateLocalTable({ tableName, columns, constraints }) {
      const localCols = columns.map((col) => {
        const [name, type] = col.split(/\s+/, 2);
        if (name === "id") return col; // ä¿ç•™ä¸»é”®åŸæ ·
        return `${name} ${type}`;
      });

      const renamedConstraints = renamePrimaryKeyConstraint(constraints, `${tableName}_local_pkey`);

      return `CREATE TABLE IF NOT EXISTS "${tableName}_local" (\n  ${[
        ...localCols,
        `"changed_columns" TEXT[]`,
        `"is_deleted" BOOLEAN NOT NULL DEFAULT FALSE`,
        `"write_id" UUID NOT NULL`,
        ...renamedConstraints,
      ].join(",\n  ")}
);`;
    }

    /**
     * ç”Ÿæˆè§†å›¾
     */
    function generateView({ tableName, columns, constraints }) {
      const colNames = columns.map((col) => col.split(/\s+/, 1)[0].replace(/^"|"$/g, ""));

      // è§£æä¸»é”®å­—æ®µ
      const pkConstraint = constraints.find((c) => c.includes("PRIMARY KEY"));
      const pkCols = pkConstraint
        ? pkConstraint
            .match(/\(([^)]+)\)/)[1]
            .split(",")
            .map((s) => s.trim().replace(/"/g, ""))
        : [];

      // å¯¹äºå…³è”è¡¨ï¼Œå¦‚æœæ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨æ‰€æœ‰åˆ—ä½œä¸ºä¸»é”®
      if (pkCols.length === 0 && tableName.startsWith("_")) {
        pkCols.push(...colNames);
      }

      // å¦‚æœä»ç„¶æ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨ UNION ALL æ–¹å¼
      if (pkCols.length === 0) {
        return `
CREATE OR REPLACE VIEW "${tableName}" AS
  SELECT
  ${colNames.map((name) => `   synced."${name}" AS "${name}"`).join(",\n")}
  FROM "${tableName}_synced" AS synced
  UNION ALL
  SELECT
  ${colNames.map((name) => `   local."${name}" AS "${name}"`).join(",\n")}
  FROM "${tableName}_local" AS local
  WHERE local."is_deleted" = FALSE;`;
      }

      const selectLines = colNames.map((name) =>
        pkCols.includes(name)
          ? `   COALESCE(local."${name}", synced."${name}") AS "${name}"`
          : `   CASE
    WHEN '${name}' = ANY(local.changed_columns)
      THEN local."${name}"
      ELSE synced."${name}"
    END AS "${name}"`,
      );

      const joinCondition = pkCols.map((pk) => `synced."${pk}" = local."${pk}"`).join(" AND ");
      const whereCondition = `(${pkCols.map((pk) => `local."${pk}" IS NULL`).join(" OR ")} OR local."is_deleted" = FALSE)`;

      const view = `
CREATE OR REPLACE VIEW "${tableName}" AS
  SELECT
  ${selectLines.join(",\n")}
  FROM "${tableName}_synced" AS synced
  FULL OUTER JOIN "${tableName}_local" AS local
  ON ${joinCondition}
  WHERE ${whereCondition};`;

      const jsonFields = colNames.map((name) => `'${name}', NEW."${name}"`).join(",\n      ");
      const updateJsonFields = colNames
        .map((name) => `'${name}', COALESCE(NEW."${name}", local."${name}")`)
        .join(",\n      ");

      const changedColsCheck = colNames
        .filter((c) => !pkCols.includes(c))
        .map(
          (name) => `
    IF NEW."${name}" IS DISTINCT FROM synced."${name}" THEN
      changed_cols := array_append(changed_cols, '${name}');
    END IF;`,
        )
        .join("");

      const triggerFnInsert = `
CREATE OR REPLACE FUNCTION ${tableName}_insert_trigger()
RETURNS TRIGGER AS $$
DECLARE
    local_write_id UUID := gen_random_uuid();
    changed_cols TEXT[] := ARRAY[]::TEXT[];
BEGIN
    -- Add all non-primary key columns to changed_columns
    ${colNames
      .filter((name) => !pkCols.includes(name))
      .map((name) => `changed_cols := array_append(changed_cols, '${name}');`)
      .join("\n    ")}

    INSERT INTO "${tableName}_local" (
    ${colNames.map((name) => `"${name}"`).join(", ")},
    changed_columns,
    write_id
    )
    VALUES (
    ${colNames.map((name) => `NEW."${name}"`).join(", ")},
    changed_cols,
    local_write_id
    );

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'insert',
    jsonb_build_object(
        ${jsonFields}
    ),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;`;

      const updateSetLines =
        colNames
          .filter((c) => !pkCols.includes(c))
          .map(
            (name) =>
              `
    "${name}" = CASE WHEN NEW."${name}" IS DISTINCT FROM synced."${name}" THEN NEW."${name}" ELSE local."${name}" END`,
          )
          .join(",") || "-- no non-pk fields";

      const triggerFnUpdate = `
CREATE OR REPLACE FUNCTION ${tableName}_update_trigger()
RETURNS TRIGGER AS $$
DECLARE
    synced "${tableName}_synced"%ROWTYPE;
    local "${tableName}_local"%ROWTYPE;
    changed_cols TEXT[] := ARRAY[]::TEXT[];
    local_write_id UUID := gen_random_uuid();
BEGIN
    SELECT * INTO synced FROM "${tableName}_synced" WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    SELECT * INTO local FROM "${tableName}_local" WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    ${changedColsCheck || "-- no non-pk fields to track"}
    IF NOT FOUND THEN
    INSERT INTO "${tableName}_local" (
        ${colNames.map((name) => `"${name}"`).join(", ")},
        changed_columns,
        write_id
    )
    VALUES (
        ${colNames.map((name) => `NEW."${name}"`).join(", ")},
        changed_cols,
        local_write_id
    );
    ELSE
    UPDATE "${tableName}_local"
    SET
        ${updateSetLines},
        changed_columns = (
        SELECT array_agg(DISTINCT col) FROM (
            SELECT unnest(local.changed_columns) AS col
            UNION
            SELECT unnest(changed_cols) AS col
        ) AS cols
        ),
        write_id = local_write_id
    WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    END IF;

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'update',
    jsonb_strip_nulls(jsonb_build_object(
        ${updateJsonFields}
    )),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;`;

      const triggerFnDelete = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_trigger()
RETURNS TRIGGER AS $$
DECLARE
    local_write_id UUID := gen_random_uuid();
BEGIN
    IF EXISTS (SELECT 1 FROM "${tableName}_local" WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")}) THEN
    UPDATE "${tableName}_local"
    SET is_deleted = TRUE,
        write_id = local_write_id
    WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")};
    ELSE
    INSERT INTO "${tableName}_local" (
        ${pkCols.join(", ")},
        "is_deleted",
        "write_id"
    )
    VALUES (
        ${pkCols.map((pk) => `OLD."${pk}"`).join(", ")},
        TRUE,
        local_write_id
    );
    END IF;

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'delete',
    jsonb_build_object(${pkCols.map((pk) => `'${pk}', OLD."${pk}"`).join(", ")}),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN OLD;
END;
$$ LANGUAGE plpgsql;`;

      const triggers = `
CREATE OR REPLACE TRIGGER ${tableName}_insert
INSTEAD OF INSERT ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_insert_trigger();

CREATE OR REPLACE TRIGGER ${tableName}_update
INSTEAD OF UPDATE ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_update_trigger();

CREATE OR REPLACE TRIGGER ${tableName}_delete
INSTEAD OF DELETE ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_trigger();
`;

      const syncedInsertUpdateCleanupFn = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_local_on_synced_insert_and_update_trigger()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM "${tableName}_local"
  WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")}
    AND write_id IS NOT NULL
    AND write_id = NEW.write_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
`;

      const syncedDeleteCleanupFn = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_local_on_synced_delete_trigger()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM "${tableName}_local"
  WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")};
  RETURN OLD;
END;
$$ LANGUAGE plpgsql;
`;

      const syncedTriggers = `
CREATE OR REPLACE TRIGGER delete_local_on_synced_insert
AFTER INSERT OR UPDATE ON "${tableName}_synced"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_local_on_synced_insert_and_update_trigger();

CREATE OR REPLACE TRIGGER delete_local_on_synced_delete
AFTER DELETE ON "${tableName}_synced"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_local_on_synced_delete_trigger();
`;

      return [
        view,
        triggerFnInsert,
        triggerFnUpdate,
        triggerFnDelete,
        triggers,
        syncedInsertUpdateCleanupFn,
        syncedDeleteCleanupFn,
        syncedTriggers,
      ].join("\n");
    }

    // åŒ¹é…å®Œæ•´çš„ SQL å—ï¼ˆåŒ…æ‹¬æ³¨é‡Šï¼‰
    const blocks = initContent
      .split(/(?=^--|^CREATE\s|^ALTER\s|^DROP\s)/gim)
      .map((block) => block.trim())
      .filter(Boolean);

    const output = [];

    for (const block of blocks) {
      if (/^CREATE\s+TABLE/i.test(block)) {
        const parsed = parseCreateTable(block);
        if (!parsed) {
          output.push(`-- âš ï¸ æ— æ³•è§£æçš„è¡¨å®šä¹‰ä¿ç•™å¦‚ä¸‹ï¼š\n${block}`);
          continue;
        }

        const { tableName } = parsed;

        output.push(`-- ${tableName}`);

        // output.push(`-- DROP original "${tableName}"`);
        // output.push(`DROP TABLE IF EXISTS "${tableName}";\n`);

        output.push(generateSyncedTable(parsed));

        output.push(generateLocalTable(parsed));

        output.push(generateView(parsed));
      } else {
        // å…¶ä½™ SQL ä¿ç•™
        output.push(block);
      }
    }

    const changesTable = `CREATE TABLE IF NOT EXISTS changes (
  id BIGSERIAL PRIMARY KEY,
  table_name TEXT NOT NULL,
  operation TEXT NOT NULL,
  value JSONB NOT NULL,
  write_id UUID NOT NULL,
  transaction_id XID8 NOT NULL
);

CREATE OR REPLACE FUNCTION changes_notify_trigger()
RETURNS TRIGGER AS $$
BEGIN
  NOTIFY changes;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE TRIGGER changes_notify
AFTER INSERT ON changes
FOR EACH ROW
EXECUTE FUNCTION changes_notify_trigger();
`;

    fs.writeFileSync(initSQLFilePath, output.join("\n") + changesTable, "utf-8");
    console.log(`âœ… å·²è½¬æ¢initSQL ${initSQLFilePath}`);
  }

  /**
   * ç”Ÿæˆ Kysely ç±»å‹
   */
  static generateKyselyTypes() {
    utils.execCommand("prisma generate --schema=db/temp_client_schema.prisma --generator=kysely");
  }

  /**
   * ä¿®å¤å…³ç³»è¡¨åç§°
   * @param {string} updatedSchema - æ›´æ–°åçš„ schema å†…å®¹
   */
  static fixRelationTableNames(updatedSchema) {
    // ä½¿ç”¨ SchemaAnalyzer è‡ªåŠ¨æ£€æµ‹éœ€è¦ä¿®å¤çš„å…³ç³»è¡¨åç§°
    const schemaAnalysis = SchemaAnalyzer.analyzeSchema(updatedSchema);
    const relationTables = schemaAnalysis.relationTables;

    // ä¿®å¤ SQL ä¸­çš„è¡¨åå¼•ç”¨
    const fixTableNames = (sql) => {
      let fixedSql = sql;
      relationTables.forEach((tableName) => {
        // æ›¿æ¢è¡¨åå¼•ç”¨ï¼Œç¡®ä¿ä½¿ç”¨åŒå¼•å·åŒ…è£¹
        const regex = new RegExp(`\\b${tableName.toLowerCase()}\\b`, "g");
        fixedSql = fixedSql.replace(regex, `"${tableName}"`);
      });
      return fixedSql;
    };

    // è¯»å–å¹¶ä¿®å¤ SQL æ–‡ä»¶
    const serverSql = utils.safeReadFile(PATHS.serverDB.sql);
    const clientSql = utils.safeReadFile(PATHS.clientDB.sql);

    // å†™å…¥ä¿®å¤åçš„ SQL æ–‡ä»¶
    utils.safeWriteFile(PATHS.serverDB.sql, fixTableNames(serverSql));
    utils.safeWriteFile(PATHS.clientDB.sql, fixTableNames(clientSql));
  }
}

/**
 * Zod Schema ç”Ÿæˆå™¨
 * è´Ÿè´£ç”Ÿæˆ Zod éªŒè¯æ¨¡å¼
 */
class ZodGenerator {
  /**
   * ç”Ÿæˆ Zod schemas
   */
  static generate() {
    // ä» db/generated/kysely/enums.ts ç”Ÿæˆ zod æšä¸¾
    const enumSchemas = this.generateEnumSchemas();

    // ä» Kysely ç±»å‹å®šä¹‰ç”Ÿæˆ Zod schemas
    const generatedSchemas = this.generateModelSchemas();

    // ç”Ÿæˆæœ€ç»ˆçš„ Zod schemas æ–‡ä»¶å†…å®¹
    const zodFileContent = `// ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹
import { z } from "zod";

${enumSchemas}
${generatedSchemas}
`;

    // å†™å…¥ Zod schemas æ–‡ä»¶
    utils.safeWriteFile(PATHS.zod.schemas, zodFileContent);
  }

  /**
   * ç”Ÿæˆæšä¸¾ schemas
   * @returns {string} æšä¸¾ schemas å†…å®¹
   */
  static generateEnumSchemas() {
    let enumSchemas = "";
    const enumMap = new Map();

    if (fs.existsSync(PATHS.kysely.enums)) {
      const enumsContent = utils.safeReadFile(PATHS.kysely.enums);
      const enumConstRegex = /export const (\w+) = \{([\s\S]*?)\} as const;/g;
      let match;

      while ((match = enumConstRegex.exec(enumsContent)) !== null) {
        const enumName = match[1];
        const body = match[2];
        const valueRegex = /['"]?\w+['"]?\s*:\s*['"]([^'"]+)['"]/g;
        let valueMatch;
        const values = [];

        while ((valueMatch = valueRegex.exec(body)) !== null) {
          values.push(valueMatch[1]);
        }

        if (values.length > 0) {
          enumSchemas += `export const ${enumName}Schema = z.enum([${values.map((v) => `"${v}"`).join(", ")}]);\n`;
          enumSchemas += `export type ${enumName}Type = z.infer<typeof ${enumName}Schema>;\n\n`;
          enumMap.set(enumName.toLowerCase(), values);
        }
      }
    }

    return enumSchemas;
  }

  /**
   * ç”Ÿæˆæ¨¡å‹ schemas
   * @returns {string} æ¨¡å‹ schemas å†…å®¹
   */
  static generateModelSchemas() {
    const kyselyTypes = utils.safeReadFile(PATHS.kysely.types);
    const parsedTypes = this.parseTypes(kyselyTypes);
    
    // ç”Ÿæˆ Zod schemas
    return Object.entries(parsedTypes)
      .map(([typeName, fields]) => {
        const schemaName = `${typeName.toLowerCase()}Schema`;
        const fieldsStr = Object.entries(fields)
          .map(([fieldName, zodType]) => `  ${fieldName}: ${zodType}`)
          .join(",\n");

        return `export const ${schemaName} = z.object({\n${fieldsStr}\n});`;
      })
      .join("\n\n");
  }

  /**
   * è½¬æ¢ç±»å‹åˆ° Zod ç±»å‹
   * @param {string} type - TypeScript ç±»å‹
   * @returns {string} Zod ç±»å‹
   */
  static convertTypeToZod(type) {
    // å¤„ç†è”åˆç±»å‹
    if (type.includes("|")) {
      const types = type.split("|").map((t) => t.trim());
      // å¦‚æœåŒ…å« nullï¼Œä½¿ç”¨ nullable()
      if (types.includes("null")) {
        const nonNullTypes = types.filter((t) => t !== "null");
        if (nonNullTypes.length === 1) {
          return `${this.convertTypeToZod(nonNullTypes[0])}.nullable()`;
        }
        return `z.union([${nonNullTypes.map((t) => this.convertTypeToZod(t)).join(", ")}]).nullable()`;
      }
      return `z.union([${types.map((t) => this.convertTypeToZod(t)).join(", ")}])`;
    }

    // å¤„ç†æ•°ç»„ç±»å‹
    if (type.endsWith("[]")) {
      const baseType = type.slice(0, -2);
      return `z.array(${this.convertTypeToZod(baseType)})`;
    }

    // å¤„ç†åŸºæœ¬ç±»å‹
    switch (type) {
      case "string":
        return "z.string()";
      case "number":
        return "z.number()";
      case "boolean":
        return "z.boolean()";
      case "Date":
      case "Timestamp":
        return "z.date()";
      case "JsonValue":
      case "InputJsonValue":
      case "unknown":
        return `z.lazy(() => z.union([
          z.string(),
          z.number(),
          z.boolean(),
          z.literal(null),
          z.record(z.lazy(() => z.union([z.any(), z.literal(null)]))),
          z.array(z.lazy(() => z.union([z.any(), z.literal(null)])))
        ]))`;
      default:
        // æ£€æŸ¥æ˜¯å¦æ˜¯æšä¸¾ç±»å‹
        if (type.endsWith("Type")) {
          const enumName = type.replace("Type", "");
          // ç¡®ä¿æšä¸¾åç§°é¦–å­—æ¯å¤§å†™
          const pascalCaseEnum = enumName.charAt(0).toUpperCase() + enumName.slice(1);
          return `${pascalCaseEnum}TypeSchema`;
        }
        // æ£€æŸ¥æ˜¯å¦æ˜¯å­—é¢é‡ç±»å‹
        if (type.startsWith('"') && type.endsWith('"')) {
          return `z.literal(${type})`;
        }
        // å¯¹äºæœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„ JSON ç±»å‹
        return `z.lazy(() => z.union([
          z.string(),
          z.number(),
          z.boolean(),
          z.literal(null),
          z.record(z.lazy(() => z.union([z.any(), z.literal(null)]))),
          z.array(z.lazy(() => z.union([z.any(), z.literal(null)])))
        ]))`;
    }
  }

  /**
   * è§£æå­—æ®µ
   * @param {string} fieldsStr - å­—æ®µå­—ç¬¦ä¸²
   * @returns {Object} å­—æ®µæ˜ å°„
   */
  static parseFields(fieldsStr) {
    const fields = {};
    const fieldRegex = /(\w+)(\?)?:\s*([^;]+);/g;
    let match;

    while ((match = fieldRegex.exec(fieldsStr)) !== null) {
      const [, name, optional, type] = match;
      const zodType = this.convertTypeToZod(type.trim());
      fields[name] = optional ? `${zodType}.nullable()` : zodType;
    }

    return fields;
  }

  /**
   * è§£æç±»å‹å®šä¹‰
   * @param {string} kyselyTypes - Kysely ç±»å‹å†…å®¹
   * @returns {Object} ç±»å‹æ˜ å°„
   */
  static parseTypes(kyselyTypes) {
    const types = {};
    const typeRegex = /export\s+type\s+(\w+)\s*=\s*\{([\s\S]*?)\};/g;
    let match;

    while ((match = typeRegex.exec(kyselyTypes)) !== null) {
      const [, typeName, fieldsStr] = match;
      
      // è·³è¿‡ä¸éœ€è¦çš„ç±»å‹
      if (
        typeName === "Generated" ||
        typeName === "Timestamp" ||
        typeName.includes("Relation") ||
        typeName.includes("To") ||
        typeName.includes("_create_data") ||
        typeName.includes("_update_data")
      ) {
        continue;
      }

      types[typeName] = this.parseFields(fieldsStr);
    }

    return types;
  }
}

/**
 * QueryBuilder ç”Ÿæˆå™¨ä¼˜åŒ–
 * è´Ÿè´£ç”Ÿæˆ QueryBuilder çš„è§„åˆ™æ–‡ä»¶
 */
class QueryBuilderGenerator {
  static generate(enumTypeToNameMap) {
    console.log("ğŸ”„ å¼€å§‹ç”Ÿæˆ QueryBuilder è§„åˆ™...");
    
    // ä½¿ç”¨å®Œæ•´çš„ EnumProcessor
    const enumProcessor = new EnumProcessor();
    const { updatedSchema } = enumProcessor.processEnums().processSchema();
    
    // è§£æ schema
    const models = schemaParser.parseModels(updatedSchema);
    const schemaEnums = schemaParser.parseEnums(updatedSchema);
    
    // åˆå¹¶æšä¸¾å®šä¹‰ï¼ˆä» EnumProcessor è·å–ï¼‰
    const allEnums = {};
    for (const [enumName, values] of enumProcessor.extractedEnums) {
      allEnums[enumName] = values;
    }
    Object.assign(allEnums, schemaEnums);
    
    let rulesContent = `// ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹
import { Fields } from "@query-builder/solid-query-builder";

// é€šç”¨æ“ä½œç¬¦é…ç½®
export const OPERATORS = {
  string: ${JSON.stringify(COMMON_OPERATORS.string, null, 2)},
  number: ${JSON.stringify(COMMON_OPERATORS.number, null, 2)},
  date: ${JSON.stringify(COMMON_OPERATORS.date, null, 2)},
  boolean: ${JSON.stringify(COMMON_OPERATORS.boolean, null, 2)},
  enum: ${JSON.stringify(COMMON_OPERATORS.enum, null, 2)},
};

// æšä¸¾å€¼é…ç½®
`;

    // ç”Ÿæˆæšä¸¾é…ç½®
    for (const [enumName, values] of Object.entries(allEnums)) {
      const pascalEnumName = utils.toPascalCase(enumName);
      rulesContent += `export const ${pascalEnumName}Enum = [
  ${values.map(v => `{ value: "${v}", label: "${v}" }`).join(",\n  ")}
];

`;
    }

    // ç”Ÿæˆå­—æ®µé…ç½®
    for (const model of models) {
      const modelName = utils.toPascalCase(model.name);
      rulesContent += `export const ${modelName}Fields: Fields[] = [
  ${model.fields.map(field => {
    const fieldName = utils.toPascalCase(field.name);
    const label = utils.generateLabel(field.name);
    const typeConfig = typeConverter.prismaToQueryBuilder(field.type, field.isOptional);
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯æšä¸¾å­—æ®µ
    let enumConfig = "";
    let valueEditorType = typeConfig.valueEditorType;
    let inputType = typeConfig.inputType;
    
    if (field.enumType) {
      // ä½¿ç”¨å·²å»ºç«‹çš„æšä¸¾æ˜ å°„
      const enumName = enumTypeToNameMap.get(field.enumType);
      
      if (enumName && allEnums[enumName]) {
        enumConfig = `,\n    values: ${utils.toPascalCase(enumName)}Enum`;
        // æšä¸¾å­—æ®µä½¿ç”¨ radio ç»„ä»¶
        valueEditorType = "radio";
        inputType = "radio";
      }
    }
    
    // æ ¹æ®å­—æ®µç±»å‹ä¼˜åŒ–é…ç½®
    let additionalConfig = "";
    if (typeConfig.comparator === "boolean") {
      // å¸ƒå°”å­—æ®µä½¿ç”¨ checkbox
      valueEditorType = "checkbox";
      inputType = "checkbox";
    } else if (typeConfig.comparator === "date") {
      // æ—¥æœŸå­—æ®µä½¿ç”¨æ–‡æœ¬è¾“å…¥ï¼ˆåº“ä¸æ”¯æŒ date ç±»å‹ï¼‰
      valueEditorType = "text";
      inputType = "text";
    } else if (typeConfig.comparator === "number") {
      // æ•°å­—å­—æ®µä½¿ç”¨æ–‡æœ¬è¾“å…¥ï¼ˆåº“ä¸æ”¯æŒ number ç±»å‹ï¼‰
      valueEditorType = "text";
      inputType = "number";
    }
    
    return `{
    name: "${fieldName}",
    label: "${label}",
    placeholder: "è¯·é€‰æ‹©æˆ–è¾“å…¥${label.toLowerCase()}",
    id: "${field.name}",
    valueEditorType: "${valueEditorType}",
    inputType: "${inputType}",
    comparator: "${typeConfig.comparator}",
    operators: OPERATORS.${typeConfig.comparator},
    defaultOperator: "${typeConfig.operators[0].value}",
    defaultValue: ${field.isOptional ? 'null' : '""'}${enumConfig}${additionalConfig}
  }`;
  }).join(",\n  ")}
];

`;
    }

    utils.safeWriteFile(PATHS.queryBuilder.rules, rulesContent);
    console.log("âœ… QueryBuilder è§„åˆ™ç”Ÿæˆå®Œæˆï¼");
    console.log(`ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:`);
    console.log(`   - æ¨¡å‹æ•°é‡: ${models.length}`);
    console.log(`   - å­—æ®µæ€»æ•°: ${models.reduce((sum, model) => sum + model.fields.length, 0)}`);
    console.log(`   - æšä¸¾æ•°é‡: ${Object.keys(allEnums).length}`);
    console.log(`   - æ–‡ä»¶å¤§å°: ${Math.round(rulesContent.length / 1024)}KB`);
  }
}

/**
 * ä¸»å‡½æ•°
 * åè°ƒæ‰€æœ‰ç”Ÿæˆå™¨çš„æ‰§è¡Œ
 */
async function main() {
  try {
    console.log("ğŸš€ å¼€å§‹ç”Ÿæˆ...");

    // ç¡®ä¿ç›®å½•å­˜åœ¨
    utils.ensureDirectories();

    // 1. å¤„ç†æšä¸¾å’Œ Schema
    console.log("ğŸ“ å¤„ç†æšä¸¾å’Œ Schema...");
    const enumProcessor = new EnumProcessor();
    const { updatedSchema, kyselyGenerator, clientGenerators } = enumProcessor.processEnums().processSchema();

    // 2. ç”Ÿæˆ SQL
    console.log("ğŸ—„ï¸ ç”Ÿæˆ SQL...");
    SQLGenerator.generate(updatedSchema, kyselyGenerator, clientGenerators, enumProcessor.enumDefinitions);

    // 3. ç”Ÿæˆ Zod schemas
    console.log("ğŸ” ç”Ÿæˆ Zod schemas...");
    ZodGenerator.generate();

    // 4. ç”Ÿæˆ Kysely ç±»å‹
    console.log("ğŸ“Š ç”Ÿæˆ Kysely ç±»å‹...");
    SQLGenerator.generateKyselyTypes();

    // 5. ç”Ÿæˆ QueryBuilder è§„åˆ™
    console.log("ğŸ”§ ç”Ÿæˆ QueryBuilder è§„åˆ™...");
    QueryBuilderGenerator.generate(enumProcessor.enumTypeToNameMap);

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    utils.cleanupTempFiles();

    console.log("âœ… æ‰€æœ‰ç”Ÿæˆå®Œæˆï¼");
  } catch (error) {
    console.error("âŒ ç”Ÿæˆå¤±è´¥:", error);
    process.exit(1);
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°
if (import.meta.url === `file://${process.argv[1]}`) {
main();
}
