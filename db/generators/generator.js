/**
 * @file generator.js
 * @description å¼€å‘ç¯å¢ƒç”Ÿæˆå™¨
 *
 * ä¸»è¦åŠŸèƒ½ï¼š
 * å°†baseSchemaå’Œenumsç»“åˆï¼Œç”ŸæˆserverSchemaå’ŒclientSchema
 * 1.sqlå¤„ç†
 * æ ¹æ®serverSchemaå’ŒclientSchemaç”ŸæˆserverDB/init.sqlå’ŒclientDB/init.sql
 * å¯¹ç”Ÿæˆçš„clientDB/init.sqlè¿›è¡Œè½¬æ¢ï¼Œä½¿å…¶èƒ½é…åˆåŒæ­¥æ¶æ„å·¥ä½œ
 * ä¿®å¤serverDB/init.sqlå’ŒclientDB/init.sqlä¸­çš„è¡¨åå¼•ç”¨ï¼Œä½¿å…¶èƒ½æ­£ç¡®å¼•ç”¨
 * 2.ç”Ÿæˆkyselyç±»å‹
 * 3.ç”Ÿæˆzodç±»å‹
 * 4.ç”ŸæˆQueryBuilderè§„åˆ™
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { createRequire } from "module";
import { execSync } from "child_process";

// å¯¼å…¥å·¥å…·æ¨¡å—
import { PATHS, GENERATOR_CONFIG } from "./utils/config.js";
import { StringUtils, FileUtils, CommandUtils, LogUtils } from "./utils/common.js";
import { TypeConverter, COMMON_OPERATORS } from "./utils/typeConverter.js";
import { SchemaParser } from "./utils/schemaParser.js";
import { EnumProcessor } from "./utils/enumProcessor.js";

const require = createRequire(import.meta.url);
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * SQL ç”Ÿæˆå™¨
 * è´Ÿè´£ç”Ÿæˆæ•°æ®åº“åˆå§‹åŒ– SQL è„šæœ¬
 */
class SQLGenerator {
  /**
   * ç”Ÿæˆ SQL æ–‡ä»¶
   * @param {string} updatedSchema - æ›´æ–°åçš„ schema å†…å®¹
   * @param {string} kyselyGenerator - Kysely generator é…ç½®
   * @param {Array} clientGenerators - å®¢æˆ·ç«¯ generators é…ç½®
   * @param {Map} enumDefinitions - æšä¸¾å®šä¹‰
   */
  static generate(updatedSchema, kyselyGenerator, clientGenerators, enumDefinitions) {
    // ç”Ÿæˆæœ€ç»ˆçš„ schema æ–‡ä»¶
    const finalSchema = updatedSchema + "\n" + Array.from(enumDefinitions.values()).join("\n\n");

    // åˆ›å»ºä¸´æ—¶ schema æ–‡ä»¶
    FileUtils.safeWriteFile(PATHS.serverDB.tempSchema, finalSchema);
    FileUtils.safeWriteFile(
      PATHS.clientDB.tempSchema,
      clientGenerators.join("\n") + "\n" + kyselyGenerator + finalSchema,
    );

    // ç”Ÿæˆ SQL æ–‡ä»¶
    CommandUtils.execCommand(
      `npx prisma migrate diff --from-empty --to-schema-datamodel ${PATHS.serverDB.tempSchema} --script > ${PATHS.serverDB.sql}`,
    );
    CommandUtils.execCommand(
      `npx prisma migrate diff --from-empty --to-schema-datamodel ${PATHS.clientDB.tempSchema} --script > ${PATHS.clientDB.sql}`,
    );

    // è½¬æ¢clientDB/init.sql
    this.transformClientSql();

    // ä¿®å¤å…³ç³»è¡¨åç§°
    this.fixRelationTableNames(updatedSchema);
  }

  /**
   * å°†clientDB/init.sqlè½¬æ¢ä¸ºæ”¯æŒåŒæ­¥æ¶æ„çš„sql
   */
  static transformClientSql() {
    const initSQLFilePath = PATHS.clientDB.sql;
    // è¯»å–æ–‡ä»¶å†…å®¹
    let initContent = fs.readFileSync(initSQLFilePath, "utf-8");

    // åˆ é™¤æ‰€æœ‰ `ALTER TABLE` è¯­å¥ä¸­æ¶‰åŠ `FOREIGN KEY` çš„è¡Œ
    initContent = initContent.replace(/ALTER TABLE .* FOREIGN KEY.*;\n?/g, "");

    // **åˆ é™¤å­¤ç«‹çš„ `-- AddForeignKey` è¡Œ**
    initContent = initContent.replace(/-- AddForeignKey\s*\n?/g, "");

    // åˆ é™¤æ‰€æœ‰çš„ `CREATE INDEX` è¯­å¥
    initContent = initContent.replace(/CREATE INDEX.*;\n?/g, "");
    initContent = initContent.replace(/CREATE UNIQUE INDEX.*;\n?/g, "");

    // **åˆ é™¤å­¤ç«‹çš„ `-- CreateIndex` è¡Œ**
    initContent = initContent.replace(/-- CreateIndex\s*\n?/g, "");

    // **å»é™¤å¯èƒ½å¤šä½™çš„ç©ºè¡Œ**
    // initContent = initContent.replace(/\n{2,}/g, "\n");

    fs.writeFileSync(initSQLFilePath, initContent, "utf-8");

    LogUtils.logSuccess("å¤–é”®çº¦æŸåŠç´¢å¼•å·²åˆ é™¤ï¼");

    ///////////////// å°†sqlè½¬æ¢æˆ  *_synced è¡¨ï¼ˆåªè¯»å‰¯æœ¬ï¼‰ï¼›*_local è¡¨ï¼ˆæœ¬åœ°çŠ¶æ€ + ä¹è§‚æ›´æ–°ï¼‰ï¼›VIEWï¼ˆåˆå¹¶è¯»å–è§†å›¾ï¼‰ï¼› ////////////////////

    /**
     * ä»åŸå§‹ CREATE TABLE è¯­å¥ä¸­æå–ç»“æ„ä¿¡æ¯
     */
    function parseCreateTable(sql) {
      // å…¼å®¹è¯¸å¦‚ï¼š
      // CREATE TABLE "public"."user" ( ... );
      // CREATE TABLE "user" ( ... );
      // CREATE TABLE public.user ( ... );
      // æ³¨æ„ï¼šå®¢æˆ·ç«¯è½¬æ¢é˜¶æ®µç»Ÿä¸€å¿½ç•¥ schemaï¼Œä½¿ç”¨è£¸è¡¨åç”Ÿæˆ *_synced/*_local/è§†å›¾
      const match = sql.match(/CREATE\s+TABLE\s+(?:"?([\w$]+)"?\.)?"?([\w$]+)"?\s*\(([\s\S]+?)\);/i);
      if (!match) return null;
      const [, _schema, rawName, body] = match;
      const tableName = rawName; // ä¸¢å¼ƒ schemaï¼Œä½¿ç”¨åŸå§‹è¡¨å
      const lines = body
        .split(/\r?\n/)
        .map((line) => line.trim())
        .filter(Boolean);

      const columns = [];
      const constraints = [];

      for (const line of lines) {
        if (line.startsWith("CONSTRAINT") || line.startsWith("PRIMARY KEY") || line.startsWith("UNIQUE")) {
          constraints.push(line.replace(/,+$/, ""));
        } else {
          columns.push(line.replace(/,+$/, ""));
        }
      }

      return { tableName, columns, constraints };
    }

    /**
     * é‡å‘½åä¸»é”®çº¦æŸ
     */
    function renamePrimaryKeyConstraint(constraints, newName) {
      return constraints.map((constraint) => {
        // å…¼å®¹æ—  CONSTRAINT åç§°çš„ PRIMARY KEY å®šä¹‰
        if (/CONSTRAINT\s+"[^"]*"\s+PRIMARY KEY/i.test(constraint)) {
          return constraint.replace(/CONSTRAINT\s+"[^"]*"\s+PRIMARY KEY/i, `CONSTRAINT "${newName}" PRIMARY KEY`);
        }
        if (/PRIMARY\s+KEY/i.test(constraint)) {
          return constraint.replace(/PRIMARY\s+KEY/i, `CONSTRAINT "${newName}" PRIMARY KEY`);
        }
        return constraint;
      });
    }

    /**
     * ç”Ÿæˆ synced è¡¨ç»“æ„
     */
    function generateSyncedTable({ tableName, columns, constraints }) {
      const renamedConstraints = renamePrimaryKeyConstraint(constraints, `${tableName}_synced_pkey`);
      const syncedCols = [...columns, `"write_id" UUID`];
      return `CREATE TABLE IF NOT EXISTS "${tableName}_synced" (\n  ${[...syncedCols, ...renamedConstraints].join(",\n  ")}\n);`;
    }

    /**
     * ç”Ÿæˆ local è¡¨ç»“æ„
     */
    function generateLocalTable({ tableName, columns, constraints }) {
      const localCols = columns.map((col) => {
        const [name, type] = col.split(/\s+/, 2);
        if (name === "id") return col; // ä¿ç•™ä¸»é”®åŸæ ·
        return `${name} ${type}`;
      });

      const renamedConstraints = renamePrimaryKeyConstraint(constraints, `${tableName}_local_pkey`);

      return `CREATE TABLE IF NOT EXISTS "${tableName}_local" (\n  ${[
        ...localCols,
        `"changed_columns" TEXT[]`,
        `"is_deleted" BOOLEAN NOT NULL DEFAULT FALSE`,
        `"write_id" UUID NOT NULL`,
        ...renamedConstraints,
      ].join(",\n  ")}
);`;
    }

    /**
     * ç”Ÿæˆè§†å›¾
     */
    function generateView({ tableName, columns, constraints }) {
      const colNames = columns.map((col) => col.split(/\s+/, 1)[0].replace(/^"|"$/g, ""));

      // è§£æä¸»é”®å­—æ®µ
      const pkConstraint = constraints.find((c) => /PRIMARY\s+KEY/i.test(c));
      const pkCols = pkConstraint
        ? pkConstraint
            .match(/\(([^)]+)\)/)[1]
            .split(",")
            .map((s) => s.trim().replace(/"/g, ""))
        : [];

      // å¯¹äºå…³è”è¡¨ï¼Œå¦‚æœæ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨æ‰€æœ‰åˆ—ä½œä¸ºä¸»é”®
      if (pkCols.length === 0 && tableName.startsWith("_")) {
        pkCols.push(...colNames);
      }

      // å¦‚æœä»ç„¶æ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨ UNION ALL æ–¹å¼
      if (pkCols.length === 0) {
        return `
CREATE OR REPLACE VIEW "${tableName}" AS
  SELECT
  ${colNames.map((name) => `   synced."${name}" AS "${name}"`).join(",\n")}
  FROM "${tableName}_synced" AS synced
  UNION ALL
  SELECT
  ${colNames.map((name) => `   local."${name}" AS "${name}"`).join(",\n")}
  FROM "${tableName}_local" AS local
  WHERE local."is_deleted" = FALSE;`;
      }

      const selectLines = colNames.map((name) =>
        pkCols.includes(name)
          ? `   COALESCE(local."${name}", synced."${name}") AS "${name}"`
          : `   CASE
    WHEN '${name}' = ANY(local.changed_columns)
      THEN local."${name}"
      ELSE synced."${name}"
    END AS "${name}"`,
      );

      const joinCondition = pkCols.length
        ? pkCols.map((pk) => `synced."${pk}" = local."${pk}"`).join(" AND ")
        : colNames.map((c) => `synced."${c}" = local."${c}"`).join(" AND ");
      const whereCondition = pkCols.length
        ? `(${pkCols.map((pk) => `local."${pk}" IS NULL`).join(" OR ")} OR local."is_deleted" = FALSE)`
        : `local."is_deleted" = FALSE`;

      const view = `
CREATE OR REPLACE VIEW "${tableName}" AS
  SELECT
  ${selectLines.join(",\n")}
  FROM "${tableName}_synced" AS synced
  FULL OUTER JOIN "${tableName}_local" AS local
  ON ${joinCondition}
  WHERE ${whereCondition};`;

      const jsonFields = colNames.map((name) => `'${name}', NEW."${name}"`).join(",\n      ");
      const updateJsonFields = colNames
        .map((name) => `'${name}', COALESCE(NEW."${name}", local."${name}")`)
        .join(",\n      ");

      const changedColsCheck = colNames
        .filter((c) => !pkCols.includes(c))
        .map(
          (name) => `
    IF NEW."${name}" IS DISTINCT FROM synced."${name}" THEN
      changed_cols := array_append(changed_cols, '${name}');
    END IF;`,
        )
        .join("");

      const triggerFnInsert = `
CREATE OR REPLACE FUNCTION ${tableName}_insert_trigger()
RETURNS TRIGGER AS $$
DECLARE
    local_write_id UUID := gen_random_uuid();
    changed_cols TEXT[] := ARRAY[]::TEXT[];
BEGIN
    -- Add all non-primary key columns to changed_columns
    ${colNames
      .filter((name) => !pkCols.includes(name))
      .map((name) => `changed_cols := array_append(changed_cols, '${name}');`)
      .join("\n    ")}

    INSERT INTO "${tableName}_local" (
    ${colNames.map((name) => `"${name}"`).join(", ")},
    changed_columns,
    write_id
    )
    VALUES (
    ${colNames.map((name) => `NEW."${name}"`).join(", ")},
    changed_cols,
    local_write_id
    );

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'insert',
    jsonb_build_object(
        ${jsonFields}
    ),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;`;

      const updateSetLines =
        colNames
          .filter((c) => !pkCols.includes(c))
          .map(
            (name) =>
              `
    "${name}" = CASE WHEN NEW."${name}" IS DISTINCT FROM synced."${name}" THEN NEW."${name}" ELSE local."${name}" END`,
          )
          .join(",") || "-- no non-pk fields";

      const triggerFnUpdate = `
CREATE OR REPLACE FUNCTION ${tableName}_update_trigger()
RETURNS TRIGGER AS $$
DECLARE
    synced "${tableName}_synced"%ROWTYPE;
    local "${tableName}_local"%ROWTYPE;
    changed_cols TEXT[] := ARRAY[]::TEXT[];
    local_write_id UUID := gen_random_uuid();
BEGIN
    SELECT * INTO synced FROM "${tableName}_synced" WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    SELECT * INTO local FROM "${tableName}_local" WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    ${changedColsCheck || "-- no non-pk fields to track"}
    IF NOT FOUND THEN
    INSERT INTO "${tableName}_local" (
        ${colNames.map((name) => `"${name}"`).join(", ")},
        changed_columns,
        write_id
    )
    VALUES (
        ${colNames.map((name) => `NEW."${name}"`).join(", ")},
        changed_cols,
        local_write_id
    );
    ELSE
    UPDATE "${tableName}_local"
    SET
        ${updateSetLines},
        changed_columns = (
        SELECT array_agg(DISTINCT col) FROM (
            SELECT unnest(local.changed_columns) AS col
            UNION
            SELECT unnest(changed_cols) AS col
        ) AS cols
        ),
        write_id = local_write_id
    WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")};
    END IF;

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'update',
    jsonb_strip_nulls(jsonb_build_object(
        ${updateJsonFields}
    )),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;`;

      const triggerFnDelete = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_trigger()
RETURNS TRIGGER AS $$
DECLARE
    local_write_id UUID := gen_random_uuid();
BEGIN
    IF EXISTS (SELECT 1 FROM "${tableName}_local" WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")}) THEN
    UPDATE "${tableName}_local"
    SET is_deleted = TRUE,
        write_id = local_write_id
    WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")};
    ELSE
    INSERT INTO "${tableName}_local" (
        ${pkCols.join(", ")},
        "is_deleted",
        "write_id"
    )
    VALUES (
        ${pkCols.map((pk) => `OLD."${pk}"`).join(", ")},
        TRUE,
        local_write_id
    );
    END IF;

    INSERT INTO changes (
    table_name,
    operation,
    value,
    write_id,
    transaction_id
    )
    VALUES (
    '${tableName}',
    'delete',
    jsonb_build_object(${pkCols.map((pk) => `'${pk}', OLD."${pk}"`).join(", ")}),
    local_write_id,
    pg_current_xact_id()
    );

    RETURN OLD;
END;
$$ LANGUAGE plpgsql;`;

      const triggers = `
CREATE OR REPLACE TRIGGER ${tableName}_insert
INSTEAD OF INSERT ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_insert_trigger();

CREATE OR REPLACE TRIGGER ${tableName}_update
INSTEAD OF UPDATE ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_update_trigger();

CREATE OR REPLACE TRIGGER ${tableName}_delete
INSTEAD OF DELETE ON "${tableName}"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_trigger();
`;

      const syncedInsertUpdateCleanupFn = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_local_on_synced_insert_and_update_trigger()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM "${tableName}_local"
  WHERE ${pkCols.map((pk) => `"${pk}" = NEW."${pk}"`).join(" AND ")}
    AND write_id IS NOT NULL
    AND write_id = NEW.write_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
`;

      const syncedDeleteCleanupFn = `
CREATE OR REPLACE FUNCTION ${tableName}_delete_local_on_synced_delete_trigger()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM "${tableName}_local"
  WHERE ${pkCols.map((pk) => `"${pk}" = OLD."${pk}"`).join(" AND ")};
  RETURN OLD;
END;
$$ LANGUAGE plpgsql;
`;

      const syncedTriggers = `
CREATE OR REPLACE TRIGGER delete_local_on_synced_insert
AFTER INSERT OR UPDATE ON "${tableName}_synced"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_local_on_synced_insert_and_update_trigger();

CREATE OR REPLACE TRIGGER delete_local_on_synced_delete
AFTER DELETE ON "${tableName}_synced"
FOR EACH ROW EXECUTE FUNCTION ${tableName}_delete_local_on_synced_delete_trigger();
`;

      return [
        view,
        triggerFnInsert,
        triggerFnUpdate,
        triggerFnDelete,
        triggers,
        syncedInsertUpdateCleanupFn,
        syncedDeleteCleanupFn,
        syncedTriggers,
      ].join("\n");
    }

    // åŒ¹é…å®Œæ•´çš„ SQL å—ï¼ˆåŒ…æ‹¬æ³¨é‡Šï¼‰
    // åˆ†å—ï¼šæŒ‰è¯­å¥èµ·å§‹æ‹†åˆ†ï¼Œä¿è¯æ³¨é‡Šä¸ CREATE TABLE åˆ†ç¦»
    const blocks = initContent
      .split(/(?=^--|^CREATE\s|^ALTER\s|^DROP\s)/gim)
      .map((block) => block.trim())
      .filter(Boolean);

    const output = [];

    for (const block of blocks) {
      if (/^CREATE\s+TABLE/i.test(block)) {
        const parsed = parseCreateTable(block);
        if (!parsed) {
          output.push(`-- âš ï¸ æ— æ³•è§£æçš„è¡¨å®šä¹‰ä¿ç•™å¦‚ä¸‹ï¼š\n${block}`);
          continue;
        }

        const { tableName } = parsed;

        output.push(`-- ${tableName}`);

        // output.push(`-- DROP original "${tableName}"`);
        // output.push(`DROP TABLE IF EXISTS "${tableName}";\n`);

        // è·³è¿‡ç³»ç»Ÿè¡¨/è§†å›¾ï¼ˆä»¥ public."_" å‰ç¼€çš„ä¸­é—´è¡¨é™¤å¤–ï¼‰
        if (parsed.tableName && parsed.tableName.toLowerCase() !== 'changes') {
          output.push(generateSyncedTable(parsed));
          output.push(generateLocalTable(parsed));
          output.push(generateView(parsed));
        }
      } else {
        // å…¶ä½™ SQL ä¿ç•™
        output.push(block);
      }
    }

    const changesTable = `CREATE TABLE IF NOT EXISTS changes (
  id BIGSERIAL PRIMARY KEY,
  table_name TEXT NOT NULL,
  operation TEXT NOT NULL,
  value JSONB NOT NULL,
  write_id UUID NOT NULL,
  transaction_id XID8 NOT NULL
);

CREATE OR REPLACE FUNCTION changes_notify_trigger()
RETURNS TRIGGER AS $$
BEGIN
  NOTIFY changes;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE TRIGGER changes_notify
AFTER INSERT ON changes
FOR EACH ROW
EXECUTE FUNCTION changes_notify_trigger();
`;

    fs.writeFileSync(initSQLFilePath, output.join("\n") + "\n" + changesTable, "utf-8");
    LogUtils.logSuccess(`å·²è½¬æ¢initSQL ${initSQLFilePath}`);
  }

  /**
   * ç”Ÿæˆ Kysely ç±»å‹
   */
  static generateKyselyTypes() {
    CommandUtils.execCommand(`prisma generate --schema=${PATHS.clientDB.tempSchema} --generator=kysely`);
  }

  /**
   * ä¿®å¤å…³ç³»è¡¨åç§°
   * @param {string} updatedSchema - æ›´æ–°åçš„ schema å†…å®¹
   */
  static fixRelationTableNames(updatedSchema) {
    // ä½¿ç”¨ SchemaParser è‡ªåŠ¨æ£€æµ‹éœ€è¦ä¿®å¤çš„å…³ç³»è¡¨åç§°
    const schemaAnalysis = SchemaParser.analyzeSchema(updatedSchema);
    const relationTables = schemaAnalysis.relationTables;

    // ä¿®å¤ SQL ä¸­çš„è¡¨åå¼•ç”¨
    const fixTableNames = (sql) => {
      let fixedSql = sql;
      relationTables.forEach((tableName) => {
        // æ›¿æ¢è¡¨åå¼•ç”¨ï¼Œç¡®ä¿ä½¿ç”¨åŒå¼•å·åŒ…è£¹
        const regex = new RegExp(`\\b${tableName.toLowerCase()}\\b`, "g");
        fixedSql = fixedSql.replace(regex, `"${tableName}"`);
      });
      return fixedSql;
    };

    // è¯»å–å¹¶ä¿®å¤ SQL æ–‡ä»¶
    const serverSql = FileUtils.safeReadFile(PATHS.serverDB.sql);
    const clientSql = FileUtils.safeReadFile(PATHS.clientDB.sql);

    // å†™å…¥ä¿®å¤åçš„ SQL æ–‡ä»¶
    FileUtils.safeWriteFile(PATHS.serverDB.sql, fixTableNames(serverSql));
    FileUtils.safeWriteFile(PATHS.clientDB.sql, fixTableNames(clientSql));
  }
}

/**
 * Zod Schema ç”Ÿæˆå™¨
 * è´Ÿè´£ç”Ÿæˆ Zod éªŒè¯æ¨¡å¼
 */
class ZodGenerator {
  /**
   * ç”Ÿæˆ Zod schemas
   */
  static generate() {
    // ä» db/generated/kysely/enums.ts ç”Ÿæˆ zod æšä¸¾
    const enumSchemas = this.generateEnumSchemas();

    // ä» Kysely ç±»å‹å®šä¹‰ç”Ÿæˆ Zod schemas
    const generatedSchemas = this.generateModelSchemas();

    // ç”Ÿæˆæœ€ç»ˆçš„ Zod schemas æ–‡ä»¶å†…å®¹
    const zodFileContent = `// ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹
import { z } from "zod";

${enumSchemas}
${generatedSchemas}
`;

    // å†™å…¥ Zod schemas æ–‡ä»¶
    FileUtils.safeWriteFile(PATHS.zod.schemas, zodFileContent);
  }

  /**
   * ç”Ÿæˆæšä¸¾ schemas
   * @returns {string} æšä¸¾ schemas å†…å®¹
   */
  static generateEnumSchemas() {
    let enumSchemas = "";
    const enumMap = new Map();

    if (fs.existsSync(PATHS.kysely.enums)) {
      const enumsContent = FileUtils.safeReadFile(PATHS.kysely.enums);
      const enumConstRegex = /export const (\w+) = \{([\s\S]*?)\} as const;/g;
      let match;

      while ((match = enumConstRegex.exec(enumsContent)) !== null) {
        const enumName = match[1];
        const body = match[2];
        const valueRegex = /['"]?\w+['"]?\s*:\s*['"]([^'"]+)['"]/g;
        let valueMatch;
        const values = [];

        while ((valueMatch = valueRegex.exec(body)) !== null) {
          values.push(valueMatch[1]);
        }

        if (values.length > 0) {
          enumSchemas += `export const ${enumName}Schema = z.enum([${values.map((v) => `"${v}"`).join(", ")}]);\n`;
          enumSchemas += `export type ${enumName}Type = z.infer<typeof ${enumName}Schema>;\n\n`;
          enumMap.set(enumName.toLowerCase(), values);
        }
      }
    }

    return enumSchemas;
  }

  /**
   * ç”Ÿæˆæ¨¡å‹ schemas
   * @returns {string} æ¨¡å‹ schemas å†…å®¹
   */
  static generateModelSchemas() {
    const kyselyTypes = FileUtils.safeReadFile(PATHS.kysely.types);
    const parsedTypes = this.parseTypes(kyselyTypes);
    
    // ç”Ÿæˆ Zod schemas
    const modelSchemas = Object.entries(parsedTypes)
      .map(([typeName, fields]) => {
        const schemaName = `${typeName.toLowerCase()}Schema`;
        const fieldsStr = Object.entries(fields)
          .map(([fieldName, zodType]) => `  ${fieldName}: ${zodType}`)
          .join(",\n");

        return `export const ${schemaName} = z.object({\n${fieldsStr}\n});`;
      })
      .join("\n\n");

    // ç”Ÿæˆ dbSchema
    const dbSchema = this.generateDbSchema(kyselyTypes);
    
    return modelSchemas + "\n\n" + dbSchema;
  }

  /**
   * ç”Ÿæˆ dbSchema
   * @param {string} kyselyTypes - Kysely ç±»å‹å†…å®¹
   * @returns {string} dbSchema å†…å®¹
   */
  static generateDbSchema(kyselyTypes) {
    // æŸ¥æ‰¾ DB ç±»å‹å®šä¹‰
    const dbTypeRegex = /export\s+type\s+DB\s*=\s*\{([\s\S]*?)\};/g;
    const dbMatch = dbTypeRegex.exec(kyselyTypes);
    
    if (!dbMatch) {
      return "";
    }

    const dbFieldsStr = dbMatch[1];
    const dbFields = this.parseFields(dbFieldsStr);
    
    // ç”Ÿæˆ dbSchema
    const fieldsStr = Object.entries(dbFields)
      .map(([fieldName, zodType]) => `  ${fieldName}: ${zodType}`)
      .join(",\n");

    return `export const dbSchema = z.object({\n${fieldsStr}\n});`;
  }

  /**
   * æ£€æŸ¥ç±»å‹æ˜¯å¦æ˜¯å…³è”ç±»å‹
   * @param {string} type - TypeScript ç±»å‹
   * @returns {boolean} æ˜¯å¦æ˜¯å…³è”ç±»å‹
   */
  static isRelationType(type) {
    // æ£€æŸ¥æ˜¯å¦æ˜¯å…³è”ç±»å‹ï¼ˆåŒ…å« To çš„ç±»å‹ï¼Œå¦‚ armorTocrystal, avatarTocharacter ç­‰ï¼‰
    if (type.includes('To') || type.includes('Relation')) {
      return true;
    }
    
    // æ£€æŸ¥æ˜¯å¦åœ¨ Kysely ç±»å‹æ–‡ä»¶ä¸­å®šä¹‰ï¼ˆå¦‚ campA, campB ç­‰ï¼‰
    if (fs.existsSync(PATHS.kysely.types)) {
      const typesContent = FileUtils.safeReadFile(PATHS.kysely.types);
      const escapedType = type.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
      const typeRegex = new RegExp(`export\\s+type\\s+${escapedType}\\s*=\\s*\\{`);
      return typeRegex.test(typesContent);
    }
    
    return false;
  }

  /**
   * æ£€æŸ¥ç±»å‹æ˜¯å¦æ˜¯æšä¸¾ç±»å‹
   * @param {string} type - TypeScript ç±»å‹
   * @returns {boolean} æ˜¯å¦æ˜¯æšä¸¾ç±»å‹
   */
  static isEnumType(type) {
    // LogUtils.logInfo(`    ğŸ” æ£€æŸ¥æšä¸¾ç±»å‹: "${type}"`);
    
    // ä» Kysely enums.ts æ–‡ä»¶ä¸­è¯»å–æšä¸¾å®šä¹‰
    if (fs.existsSync(PATHS.kysely.enums)) {
      // LogUtils.logInfo(`    ğŸ“ Kysely enums æ–‡ä»¶å­˜åœ¨: ${PATHS.kysely.enums}`);
      const enumsContent = FileUtils.safeReadFile(PATHS.kysely.enums);
      
      // æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„æšä¸¾å®šä¹‰
      const enumRegex = new RegExp(`export const ${type.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')} = \\{`);
      // LogUtils.logInfo(`    ğŸ” æœç´¢æ¨¡å¼: export const ${type} = {`);
      
      const isMatch = enumRegex.test(enumsContent);
      // LogUtils.logInfo(`    ${isMatch ? 'âœ…' : 'âŒ'} æšä¸¾åŒ¹é…ç»“æœ: ${isMatch}`);
      
      // if (!isMatch) {
      //   // æ˜¾ç¤ºæ–‡ä»¶ä¸­çš„å‰å‡ è¡Œæ¥å¸®åŠ©è°ƒè¯•
      //   const lines = enumsContent.split('\n').slice(0, 10);
      //   LogUtils.logInfo(`    ğŸ“„ æ–‡ä»¶å‰10è¡Œ:`);
      //   lines.forEach((line, index) => {
      //     LogUtils.logInfo(`      ${index + 1}: ${line}`);
      //   });
      // }
      
      return isMatch;
    } else {
      // LogUtils.logInfo(`    âŒ Kysely enums æ–‡ä»¶ä¸å­˜åœ¨: ${PATHS.kysely.enums}`);
      return false;
    }
  }

  /**
   * è½¬æ¢ç±»å‹åˆ° Zod ç±»å‹
   * @param {string} type - TypeScript ç±»å‹
   * @returns {string} Zod ç±»å‹
   */
  static convertTypeToZod(type) {
    // LogUtils.logInfo(`ğŸ”„ è½¬æ¢ç±»å‹: "${type}"`);
    
    // å¤„ç†è”åˆç±»å‹
    if (type.includes("|")) {
      // LogUtils.logInfo(`  ğŸ“‹ æ£€æµ‹åˆ°è”åˆç±»å‹: ${type}`);
      const types = type.split("|").map((t) => t.trim());
      // å¦‚æœåŒ…å« nullï¼Œä½¿ç”¨ nullable()
      if (types.includes("null")) {
        const nonNullTypes = types.filter((t) => t !== "null");
        if (nonNullTypes.length === 1) {
          const result = `${this.convertTypeToZod(nonNullTypes[0])}.nullable()`;
          // LogUtils.logInfo(`  âœ… è”åˆç±»å‹ç»“æœ: ${result}`);
          return result;
        }
        const result = `z.union([${nonNullTypes.map((t) => this.convertTypeToZod(t)).join(", ")}]).nullable()`;
        // LogUtils.logInfo(`  âœ… è”åˆç±»å‹ç»“æœ: ${result}`);
        return result;
      }
      const result = `z.union([${types.map((t) => this.convertTypeToZod(t)).join(", ")}])`;
      // LogUtils.logInfo(`  âœ… è”åˆç±»å‹ç»“æœ: ${result}`);
      return result;
    }

    // å¤„ç†æ•°ç»„ç±»å‹
    if (type.endsWith("[]")) {
      // LogUtils.logInfo(`  ğŸ“‹ æ£€æµ‹åˆ°æ•°ç»„ç±»å‹: ${type}`);
      const baseType = type.slice(0, -2);
      const result = `z.array(${this.convertTypeToZod(baseType)}).nullable()`;
      // LogUtils.logInfo(`  âœ… æ•°ç»„ç±»å‹ç»“æœ: ${result}`);
      return result;
    }

    // å¤„ç†åŸºæœ¬ç±»å‹
    // LogUtils.logInfo(`  ğŸ” æ£€æŸ¥åŸºæœ¬ç±»å‹: "${type}"`);
    switch (type) {
      case "string":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: string -> z.string()`);
        return "z.string()";
      case "number":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: number -> z.number()`);
        return "z.number()";
      case "boolean":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: boolean -> z.boolean()`);
        return "z.boolean()";
      case "Date":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: ${type} -> z.date()`);
        return "z.date()";
      case "Timestamp":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: ${type} -> z.date()`);
        return "z.any()"; // ä»æ•°æ®åº“æŸ¥è¯¢è¿”å›çš„ Timestamp ç±»å‹æ˜¯ Date
      case "JsonValue":
      case "InputJsonValue":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: ${type} -> JSONç±»å‹`);
        return `z.lazy(() => z.union([
          z.string(),
          z.number(),
          z.boolean(),
          z.literal(null),
          z.record(z.lazy(() => z.union([z.any(), z.literal(null)]))),
          z.array(z.lazy(() => z.union([z.any(), z.literal(null)])))
        ]))`;
      case "unknown":
        // LogUtils.logInfo(`  âœ… åŒ¹é…åŸºæœ¬ç±»å‹: unknown -> z.unknown()`);
        return `z.unknown()`;
      default:
        // LogUtils.logInfo(`  âŒ æœªåŒ¹é…åŸºæœ¬ç±»å‹ï¼Œè¿›å…¥é»˜è®¤å¤„ç†: "${type}"`);
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯æšä¸¾ç±»å‹ï¼ˆä»¥ Type ç»“å°¾ï¼‰
        if (type.endsWith("Type")) {
          // LogUtils.logInfo(`  ğŸ” æ£€æµ‹åˆ°æšä¸¾ç±»å‹ï¼ˆTypeç»“å°¾ï¼‰: ${type}`);
          const enumName = type.replace("Type", "");
          // ç¡®ä¿æšä¸¾åç§°é¦–å­—æ¯å¤§å†™
          const pascalCaseEnum = enumName.charAt(0).toUpperCase() + enumName.slice(1);
          const result = `${pascalCaseEnum}TypeSchema`;
          // LogUtils.logInfo(`  âœ… æšä¸¾ç±»å‹ç»“æœ: ${result}`);
          return result;
        }
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥çš„æšä¸¾ç±»å‹ï¼ˆå¦‚ MobDifficultyFlagï¼‰
        // LogUtils.logInfo(`  ğŸ” æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥æšä¸¾ç±»å‹: ${type}`);
        if (this.isEnumType(type)) {
          const result = `${type}Schema`;
          // LogUtils.logInfo(`  âœ… ç›´æ¥æšä¸¾ç±»å‹ç»“æœ: ${result}`);
          return result;
        } else {
          // LogUtils.logInfo(`  âŒ ä¸æ˜¯ç›´æ¥æšä¸¾ç±»å‹: ${type}`);
        }
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯å…³è”ç±»å‹ï¼ˆå¦‚ armorTocrystal, avatarTocharacter ç­‰ï¼‰
        if (this.isRelationType(type)) {
          const result = `${type.toLowerCase()}Schema`;
          // LogUtils.logInfo(`  âœ… å…³è”ç±»å‹ç»“æœ: ${result}`);
          return result;
        }
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯å­—é¢é‡ç±»å‹
        if (type.startsWith('"') && type.endsWith('"')) {
          // LogUtils.logInfo(`  âœ… æ£€æµ‹åˆ°å­—é¢é‡ç±»å‹: ${type}`);
          const result = `z.literal(${type})`;
          // LogUtils.logInfo(`  âœ… å­—é¢é‡ç±»å‹ç»“æœ: ${result}`);
          return result;
        }
        
        // å¯¹äºæœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„ JSON ç±»å‹
        // LogUtils.logInfo(`  âš ï¸  æœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨é€šç”¨JSONç±»å‹: ${type}`);
        const result = `z.lazy(() => z.union([
          z.string(),
          z.number(),
          z.boolean(),
          z.literal(null),
          z.record(z.lazy(() => z.union([z.any(), z.literal(null)]))),
          z.array(z.lazy(() => z.union([z.any(), z.literal(null)])))
        ]))`;
        // LogUtils.logInfo(`  âœ… é€šç”¨JSONç±»å‹ç»“æœ: ${result}`);
        return result;
    }
  }

  /**
   * è§£æå­—æ®µ
   * @param {string} fieldsStr - å­—æ®µå­—ç¬¦ä¸²
   * @returns {Object} å­—æ®µæ˜ å°„
   */
  static parseFields(fieldsStr) {
    const fields = {};
    const fieldRegex = /(\w+)(\?)?:\s*([^;]+);/g;
    let match;

    while ((match = fieldRegex.exec(fieldsStr)) !== null) {
      const [, name, optional, type] = match;
      const zodType = this.convertTypeToZod(type.trim());
      fields[name] = optional ? `${zodType}.nullable()` : zodType;
    }

    return fields;
  }

  /**
   * è§£æç±»å‹å®šä¹‰
   * @param {string} kyselyTypes - Kysely ç±»å‹å†…å®¹
   * @returns {Object} ç±»å‹æ˜ å°„
   */
  static parseTypes(kyselyTypes) {
    const types = {};
    const typeRegex = /export\s+type\s+(\w+)\s*=\s*\{([\s\S]*?)\};/g;
    let match;

    while ((match = typeRegex.exec(kyselyTypes)) !== null) {
      const [, typeName, fieldsStr] = match;
      
      // è·³è¿‡ä¸éœ€è¦çš„ç±»å‹
      if (
        typeName === "Generated" ||
        typeName === "Timestamp" ||
        typeName === "DB"
      ) {
        continue;
      }

      types[typeName] = this.parseFields(fieldsStr);
    }

    return types;
  }
}

/**
 * QueryBuilder ç”Ÿæˆå™¨ä¼˜åŒ–
 * è´Ÿè´£ç”Ÿæˆ QueryBuilder çš„è§„åˆ™æ–‡ä»¶
 */
class QueryBuilderGenerator {
  static generate(enumTypeToNameMap) {
    LogUtils.logStep("QueryBuilder", "å¼€å§‹ç”Ÿæˆ QueryBuilder è§„åˆ™");
    
    // ä½¿ç”¨å®Œæ•´çš„ EnumProcessor
    const enumProcessor = new EnumProcessor();
    const { updatedSchema } = enumProcessor.processEnums().processSchema();
    
    // è§£æ schema
    const models = SchemaParser.parseDetailedModels(updatedSchema);
    const schemaEnums = SchemaParser.parseEnums(updatedSchema);
    
    // åˆå¹¶æšä¸¾å®šä¹‰ï¼ˆä» EnumProcessor è·å–ï¼‰
    const allEnums = {};
    for (const [enumName, values] of enumProcessor.getExtractedEnums()) {
      allEnums[enumName] = values;
    }
    Object.assign(allEnums, schemaEnums);
    
    let rulesContent = `// ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹
import { Fields } from "@query-builder/solid-query-builder";

// é€šç”¨æ“ä½œç¬¦é…ç½®
export const OPERATORS = {
  string: ${JSON.stringify(COMMON_OPERATORS.string, null, 2)},
  number: ${JSON.stringify(COMMON_OPERATORS.number, null, 2)},
  date: ${JSON.stringify(COMMON_OPERATORS.date, null, 2)},
  boolean: ${JSON.stringify(COMMON_OPERATORS.boolean, null, 2)},
  enum: ${JSON.stringify(COMMON_OPERATORS.enum, null, 2)},
};

// æšä¸¾å€¼é…ç½®
`;

    // ç”Ÿæˆæšä¸¾é…ç½®
    for (const [enumName, values] of Object.entries(allEnums)) {
      const pascalEnumName = StringUtils.toPascalCase(enumName);
      rulesContent += `export const ${pascalEnumName}Enum = [
  ${values.map(v => `{ value: "${v}", label: "${v}" }`).join(",\n  ")}
];

`;
    }

    // ç”Ÿæˆå­—æ®µé…ç½®
    for (const model of models) {
      const modelName = StringUtils.toPascalCase(model.name);
      rulesContent += `export const ${modelName}Fields: Fields[] = [
  ${model.fields.map(field => {
    const fieldName = StringUtils.toPascalCase(field.name);
    const label = StringUtils.generateLabel(field.name);
          const typeConfig = TypeConverter.prismaToQueryBuilder(field.type, field.isOptional);
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯æšä¸¾å­—æ®µ
    let enumConfig = "";
    let valueEditorType = typeConfig.valueEditorType;
    let inputType = typeConfig.inputType;
    
    if (field.enumType) {
      // ä½¿ç”¨å·²å»ºç«‹çš„æšä¸¾æ˜ å°„
      const enumName = enumTypeToNameMap.get(field.enumType);
      
      if (enumName && allEnums[enumName]) {
        enumConfig = `,\n    values: ${StringUtils.toPascalCase(enumName)}Enum`;
        // æšä¸¾å­—æ®µä½¿ç”¨ radio ç»„ä»¶
        valueEditorType = "radio";
        inputType = "radio";
      }
    }
    
    // æ ¹æ®å­—æ®µç±»å‹ä¼˜åŒ–é…ç½®
    let additionalConfig = "";
    if (typeConfig.comparator === "boolean") {
      // å¸ƒå°”å­—æ®µä½¿ç”¨ checkbox
      valueEditorType = "checkbox";
      inputType = "checkbox";
    } else if (typeConfig.comparator === "date") {
      // æ—¥æœŸå­—æ®µä½¿ç”¨æ–‡æœ¬è¾“å…¥ï¼ˆåº“ä¸æ”¯æŒ date ç±»å‹ï¼‰
      valueEditorType = "text";
      inputType = "text";
    } else if (typeConfig.comparator === "number") {
      // æ•°å­—å­—æ®µä½¿ç”¨æ–‡æœ¬è¾“å…¥ï¼ˆåº“ä¸æ”¯æŒ number ç±»å‹ï¼‰
      valueEditorType = "text";
      inputType = "number";
    }
    
    return `{
    name: "${fieldName}",
    label: "${label}",
    placeholder: "è¯·é€‰æ‹©æˆ–è¾“å…¥${label.toLowerCase()}",
    id: "${field.name}",
    valueEditorType: "${valueEditorType}",
    inputType: "${inputType}",
    comparator: "${typeConfig.comparator}",
    operators: OPERATORS.${typeConfig.comparator},
    defaultOperator: "${typeConfig.operators[0].value}",
    defaultValue: ${field.isOptional ? 'null' : '""'}${enumConfig}${additionalConfig}
  }`;
  }).join(",\n  ")}
];

`;
    }

    FileUtils.safeWriteFile(PATHS.queryBuilder.rules, rulesContent);
    LogUtils.logSuccess("QueryBuilder è§„åˆ™ç”Ÿæˆå®Œæˆï¼");
    
    const stats = {
      "æ¨¡å‹æ•°é‡": models.length,
      "å­—æ®µæ€»æ•°": models.reduce((sum, model) => sum + model.fields.length, 0),
      "æšä¸¾æ•°é‡": Object.keys(allEnums).length,
      "æ–‡ä»¶å¤§å°": `${Math.round(rulesContent.length / 1024)}KB`
    };
    console.log(LogUtils.formatStats(stats));
  }
}

/**
 * ä¸»å‡½æ•°
 * åè°ƒæ‰€æœ‰ç”Ÿæˆå™¨çš„æ‰§è¡Œ
 */
async function main() {
  try {
    LogUtils.logStep("åˆå§‹åŒ–", "å¼€å§‹ç”Ÿæˆ...");

    // ç¡®ä¿ç›®å½•å­˜åœ¨
    FileUtils.ensureDirectories(GENERATOR_CONFIG.directories);

    // 1. å¤„ç†æšä¸¾å’Œ Schema
    LogUtils.logStep("æšä¸¾å¤„ç†", "å¤„ç†æšä¸¾å’Œ Schema");
    const enumProcessor = new EnumProcessor();
    const { updatedSchema, kyselyGenerator, clientGenerators } = enumProcessor.processEnums().processSchema();

    // 2. ç”Ÿæˆ SQL
    LogUtils.logStep("SQLç”Ÿæˆ", "ç”Ÿæˆ SQL");
    SQLGenerator.generate(updatedSchema, kyselyGenerator, clientGenerators, enumProcessor.getEnumDefinitions());

    // 3. ç”Ÿæˆ Kysely ç±»å‹
    LogUtils.logStep("Kyselyç”Ÿæˆ", "ç”Ÿæˆ Kysely ç±»å‹");
    SQLGenerator.generateKyselyTypes();

    // 4. ç”Ÿæˆ Zod schemas (ç§»åˆ°Kyselyç±»å‹ç”Ÿæˆä¹‹å)
    LogUtils.logStep("Zodç”Ÿæˆ", "ç”Ÿæˆ Zod schemas");
    ZodGenerator.generate();

    // 5. ç”Ÿæˆ QueryBuilder è§„åˆ™
    LogUtils.logStep("QueryBuilderç”Ÿæˆ", "ç”Ÿæˆ QueryBuilder è§„åˆ™");
    QueryBuilderGenerator.generate(enumProcessor.getEnumTypeToNameMap());

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    FileUtils.cleanupTempFiles(GENERATOR_CONFIG.tempFiles);

    LogUtils.logSuccess("æ‰€æœ‰ç”Ÿæˆå®Œæˆï¼");
  } catch (error) {
    LogUtils.logError("ç”Ÿæˆå¤±è´¥", error);
    process.exit(1);
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°
if (import.meta.url === `file://${process.argv[1]}`) {
main();
}
