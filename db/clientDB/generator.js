import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const enumsFilePath = path.join(__dirname, "enums.ts");
const baseSchemaPath = path.join(__dirname, "baseSchema.prisma");
const outputSchemaPath = path.join(__dirname, "generated/schema.prisma");
const dataEnumsPath = path.join(__dirname, "generated/dataEnums.ts");

// **é¢„å¤„ç† enums.tsï¼Œå»é™¤æ‰€æœ‰æ³¨é‡Š**
let enumsContent = fs.readFileSync(enumsFilePath, "utf-8");
enumsContent = enumsContent.replace(/\/\*[\s\S]*?\*\//g, ""); // åˆ é™¤ /* */ å—æ³¨é‡Š
enumsContent = enumsContent.replace(/\/\/[^\n]*/g, ""); // åˆ é™¤ // å•è¡Œæ³¨é‡Š

// **ç¬¬ä¸€æ­¥ï¼šè§£ææ•°ç»„**
const arrayRegex = /export const (\w+)\s*=\s*\[\s*([^]+?)\s*\]\s*as const;/g;
const extractedArrays = new Map();

let match;
while ((match = arrayRegex.exec(enumsContent)) !== null) {
  const arrayName = match[1];
  const values = match[2]
    .split(",")
    .map((v) => v.split("//")[0].trim().replace(/["']/g, "")) // å»æ‰å•è¡Œæ³¨é‡Š
    .filter((v) => v.length > 0);

  extractedArrays.set(arrayName, values);
  console.log(`âœ… è§£ææ•°ç»„: ${arrayName} -> ${values.join(", ")}`);
}

// **ç¬¬äºŒæ­¥ï¼šè§£æå¯¹è±¡**
const objectRegex = /export const (\w+)\s*=\s*\{([^}]+)\}\s*as const;/g;
const fieldRegex = /(\w+):\s*\[\s*([^]+?)\s*\]/g;
const enumsMap = new Map();

while ((match = objectRegex.exec(enumsContent)) !== null) {
  const modelName = match[1];
  const objectBody = match[2];

  const fieldMap = new Map();

  let fieldMatch;
  while ((fieldMatch = fieldRegex.exec(objectBody)) !== null) {
    const fieldName = fieldMatch[1];
    const rawValues = fieldMatch[2]
      .split(",")
      .map((v) => v.split("//")[0].trim().replace(/["']/g, "")) // å»æ‰å•è¡Œæ³¨é‡Š
      .filter((v) => v.length > 0);

    const values = [];
    for (const value of rawValues) {
      if (value.startsWith("...")) {
        const referencedArray = value.slice(3);
        if (extractedArrays.has(referencedArray)) {
          values.push(...extractedArrays.get(referencedArray));
          console.log(`ğŸ”„ å±•å¼€ ${referencedArray} -> ${extractedArrays.get(referencedArray).join(", ")}`);
        } else {
          console.warn(`âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° ${referencedArray}ï¼Œæ— æ³•å±•å¼€`);
        }
      } else {
        values.push(value);
      }
    }

    fieldMap.set(fieldName, values);
  }

  if (fieldMap.size > 0) {
    enumsMap.set(modelName, fieldMap);
    console.log(`âœ… è§£æå¯¹è±¡: ${modelName}`);
  }
}

// **ç¬¬ä¸‰æ­¥ï¼šè¯»å– baseSchema.prisma å¹¶æ›¿æ¢æšä¸¾**
const schemaContent = fs.readFileSync(baseSchemaPath, "utf-8");
const lines = schemaContent.split("\n");

let newSchema = "";
const enumDefinitions = [];

let currentModel = "";
for (const line of lines) {
  const modelMatch = line.match(/model (\w+) {/);
  if (modelMatch) {
    currentModel = modelMatch[1];
  } else if (line.trim() === "}") {
    currentModel = "";
  }

  let newLine = line;

  if (currentModel && enumsMap.has(currentModel)) {
    const fieldMatch = line.match(/\s*(\w+)\s+String/);
    if (fieldMatch) {
      const fieldName = fieldMatch[1];
      const enumValues = enumsMap.get(currentModel)?.get(fieldName);

      if (enumValues) {
        const enumName = `${currentModel}_${fieldName}`;
        newLine = newLine.replace("String", enumName);

        if (!enumDefinitions.some((e) => e.includes(`enum ${enumName}`))) {
          enumDefinitions.push(`enum ${enumName} {\n  ${enumValues.join("\n  ")}\n}`);
          console.log(`âœ… ç”Ÿæˆæšä¸¾: ${enumName} -> ${enumValues.join(", ")}`);
        }
      }
    }
  }

  newSchema += newLine + "\n";
}

const finalSchema = newSchema + "\n" + enumDefinitions.join("\n\n");
fs.mkdirSync(path.dirname(outputSchemaPath))
fs.writeFileSync(outputSchemaPath, finalSchema, "utf-8");

console.log("âœ… schema.prisma ç”Ÿæˆå®Œæˆï¼");



// **ç¬¬å››æ­¥ï¼šç”Ÿæˆ dataEnums.ts**
const dataEnums = {};
for (const [modelName, fields] of enumsMap.entries()) {
  dataEnums[modelName] = {};
  for (const [fieldName, values] of fields.entries()) {
    dataEnums[modelName][fieldName] = Object.fromEntries(values.map((v) => [v, ""]));
  }
}

const dataEnumsContent = `/* âš ï¸ æœ¬æ–‡ä»¶ç”± Node.js ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹ï¼ */

export const dataEnums = ${JSON.stringify(dataEnums, null, 2)} as const;

export type DataEnums = {
${Object.entries(dataEnums)
  .map(([modelName, fields]) => {
    return `  ${modelName}: {\n${Object.entries(fields)
      .map(([fieldName, values]) => `    ${fieldName}: { ${Object.keys(values).map((v) => `${v}: string`).join("; ")} };`)
      .join("\n")}\n  };`;
  })
  .join("\n")}
};`;

fs.writeFileSync(dataEnumsPath, dataEnumsContent, "utf-8");
console.log("âœ… dataEnums.ts ç”Ÿæˆå®Œæˆï¼");
